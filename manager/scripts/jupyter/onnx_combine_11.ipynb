{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights\n",
    "import onnxruntime as ort\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OnnxCombineModel(nn.Module):\n",
    "    def __init__(self,  model_path1 , model_path2 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.session1 = ort.InferenceSession(model_path1)\n",
    "        self.session2 = ort.InferenceSession(model_path2)\n",
    "        self.input_names1 = [inp.name for inp in self.session1.get_inputs()]\n",
    "        self.input_names2 = [inp.name for inp in self.session2.get_inputs()]\n",
    "\n",
    "    def forward(self, image, demographics):\n",
    "        print(self.input_names1)\n",
    "        print(self.input_names2)\n",
    "        inputs1 = {self.input_names1[0]: image, self.input_names1[1]: demographics}\n",
    "        # inputs2 = {self.input_names2[0]: image} ### 43  84 model ###\n",
    "        inputs2 = {self.input_names2[0]: image, self.input_names2[1]: demographics} ### 108 grose model ###\n",
    "        \n",
    "        outputs1 = self.session1.run(None, inputs1)\n",
    "        outputs2 = self.session2.run(None, inputs2) \n",
    "\n",
    "        probs1 = outputs1[0].flatten()\n",
    "                \n",
    "        print(probs1)\n",
    "        \n",
    "        probs1 = F.softmax(torch.tensor(probs1) , dim = 0)\n",
    "        \n",
    "        probs2 = outputs2[0].flatten()  ### 43 84 model ###\n",
    "        print(probs2)\n",
    "        \n",
    "        probs2 = F.softmax(torch.tensor(probs2) , dim = 0)\n",
    "        probs = (probs1*0.5 + 0.5*probs2)\n",
    "\n",
    "        print(probs1)\n",
    "        print(probs2)\n",
    "        print(probs)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecea595",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH_1 = \"/home/mateo/cancer-ai/manager/models/2025-11-27/grose/skin_bmodel01.onnx\"\n",
    "MODEL_PATH_2 = \"/home/mateo/cancer-ai/manager/models/2025-11-27/grose/skin_bmodel13.onnx\"\n",
    "MODEL_PATH_3 = \"/home/mateo/cancer-ai/manager/models/2025-11-27/grose/skin_new.onnx\"\n",
    "IMAGE_DATA_PATH = \"/home/mateo/cancer-ai/manager/dataset/dataset00014/1f2a5ba2-3e46-43e1-8b74-0068188a24bd.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d325099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "model = OnnxCombineModel(MODEL_PATH_1, MODEL_PATH_2)\n",
    "device = \"cpu\"\n",
    "image = Image.open(IMAGE_DATA_PATH).convert(\"RGB\")\n",
    "image = image.resize((512, 512))\n",
    "image = np.array(image, dtype=np.float32)\n",
    "image = image * (1.0 / 255.0)\n",
    "\n",
    "image = np.transpose(image, (2, 0, 1))\n",
    "image = torch.from_numpy(image).to(device)\n",
    "image = image.unsqueeze(0)\n",
    "# print(image.shape)\n",
    "data = torch.tensor([30, 0, 3], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "image = image.numpy()\n",
    "data = data.numpy()\n",
    "result = model(image, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import onnxruntime as ort\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"AKIEC\",\n",
    "    \"BCC\", \n",
    "    \"BEN_OTH\",\n",
    "    \"BKL\",\n",
    "    \"DF\",\n",
    "    \"INF\",\n",
    "    \"MAL_OTH\",\n",
    "    \"MEL\",\n",
    "    \"NV\",\n",
    "    \"SCCKA\",\n",
    "    \"VASC\"\n",
    "]\n",
    "\n",
    "class ONNXInference:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize ONNX model session.\"\"\"\n",
    "\n",
    "        self.session = ort.InferenceSession(model_path)\n",
    "        self.input_names = [inp.name for inp in self.session.get_inputs()]\n",
    "        \n",
    "        # Image preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess image to [0,1] range as specified.\"\"\"\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        # Resize to 512x512\n",
    "        img = img.resize((512, 512))\n",
    "        # Convert to numpy array with [0,1] range\n",
    "        img_array = np.array(img, dtype=np.float32)\n",
    "        # Scale from [0,255] to [0,1]\n",
    "        img_array = img_array * (1 / 255.0)\n",
    "        # Convert to BCHW format\n",
    "        img_array = np.transpose(img_array, (2, 0, 1))\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        return img_array\n",
    "    \n",
    "    def predict(self, image_path, age, gender, location):\n",
    "        \"\"\"Run inference on a single image with demographic data.\"\"\"\n",
    "        # Preprocess image\n",
    "        image_tensor = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Convert demographics to proper format\n",
    "        # Gender: 'm' -> 1.0, 'f' -> 0.0\n",
    "        gender_encoded = 1.0 if gender.lower() == 'm' else 0.0\n",
    "        \n",
    "        # Prepare demographic data as [age, gender_encoded, location]\n",
    "        demo_tensor = np.array([[float(age), gender_encoded, float(location)]], dtype=np.float32)\n",
    "        \n",
    "        # Run inference\n",
    "        inputs = {self.input_names[0]: image_tensor, self.input_names[1]: demo_tensor}\n",
    "        outputs = self.session.run(None, inputs)\n",
    "        \n",
    "        # Model already outputs probabilities (softmax applied in forward pass)\n",
    "        probs = outputs[0].flatten()\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        top3_idx = np.argsort(probs)[-3:][::-1]\n",
    "        top3 = [(CLASS_NAMES[i], float(probs[i])) for i in top3_idx]\n",
    "        \n",
    "        return top3\n",
    "\n",
    "print(\"----------------\")\n",
    "onnx_model = ONNXInference(\"model/tricorder-3/30_new.onnx\")\n",
    "predictions = onnx_model.predict(f\"example_dataset/dataset00092/a954cebc-6d49-4750-b485-851a307ab3fb.jpg\", 30 , \"f\" , 3)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a0521",
   "metadata": {},
   "source": [
    "### Combine with 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7357fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in [\"ReduceL2\", \"ReduceMean\"]:\n",
    "            debug_nodes.append(\n",
    "                {\n",
    "                    \"name\": node.name,\n",
    "                    \"op\": node.op,\n",
    "                    \"inputs_count\": len(node.inputs),\n",
    "                    \"inputs_types\": [type(inp).__name__ for inp in node.inputs],\n",
    "                    \"second_input_name\": (\n",
    "                        node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (\n",
    "                        c_node.op == \"Constant\"\n",
    "                        and c_node.outputs\n",
    "                        and len(c_node.outputs) == 1\n",
    "                        and c_node.outputs[0].name == axes_var.name\n",
    "                    ):\n",
    "                        constant_node = c_node\n",
    "                        if \"value\" in c_node.attrs:\n",
    "                            axes_values = c_node.attrs[\"value\"].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs[\"axes\"] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if \"keepdims\" not in node.attrs:\n",
    "                        node.attrs[\"keepdims\"] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\"\n",
    "                    )\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\"\n",
    "                    )\n",
    "    if debug_nodes:\n",
    "        print(\n",
    "            f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\"\n",
    "        )\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(\n",
    "                f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\"\n",
    "            )\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(\n",
    "    graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None\n",
    "):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename the shared input Variable object.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    tensors = list(graph.tensors().values())\n",
    "    for var in tensors:\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(model_path1, model_path2, output_path=\"combined.onnx\"):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one:\n",
    "    - Model1: takes 'image' and 'demographics' -> logits1\n",
    "    - Model2: takes 'image' -> logits2\n",
    "    - Combined: takes 'image' and 'demographics' -> (softmax(logits1) + logits2) / 2\n",
    "\n",
    "    Key changes vs. earlier: we rename the second graph's tensors/nodes with a prefix to avoid name collisions\n",
    "    and ensure the shared `image` input variable object is used by both graphs. This prevents duplicate tensor\n",
    "    names and topological ordering issues during checker validation.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Rename for clarity and sharing\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = \"image\"\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = \"demographics\"\n",
    "\n",
    "    # Grab model2's image input object BEFORE renaming so we can skip renaming that specific Variable\n",
    "    old_image_input = graph2.inputs[0]\n",
    "    old_demo_input = graph2.inputs[1]\n",
    "\n",
    "    # Rename graph2 tensors/nodes to avoid clashes (but don't rename the image Variable object)\n",
    "    _rename_graph_tensors_and_nodes(graph2, prefix='g2_', skip_vars=[old_image_input, old_demo_input])\n",
    "    # _rename_graph_tensors_and_nodes(graph2, prefix=\"g2_\", skip_vars=[old_image_input])\n",
    "\n",
    "    # Replace all references in graph2 nodes from old_image_input to the shared image_input object\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = image_input\n",
    "            if node.inputs[i] is old_demo_input:\n",
    "                node.inputs[i] = demographics_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared input object (this removes a duplicate input with same name)\n",
    "    graph2.inputs[0] = image_input\n",
    "    graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = \"logits1\"\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = \"logits2\"\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 11  # Fallback assumption based on reported output size\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 11]  # Fallback\n",
    "        num_classes = 11\n",
    "        print(\n",
    "            f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 10]\"\n",
    "        )\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define output variables WITH dtype and shape (no flattening)\n",
    "    probs1 = gs.Variable(\"probs1\", shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    probs2 = gs.Variable(\"probs2\", shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    sum_avg = gs.Variable(\"sum_avg\", shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output1 = gs.Variable(\n",
    "        \"avg_output1\", shape=output_shape, dtype=onnx.TensorProto.FLOAT\n",
    "    )\n",
    "    avg_output2 = gs.Variable(\n",
    "        \"avg_output2\", shape=output_shape, dtype=onnx.TensorProto.FLOAT\n",
    "    )\n",
    "\n",
    "    # Softmax on first model (axis=1 for [batch, classes])\n",
    "    softmax1 = gs.Node(\n",
    "        op=\"Softmax\", inputs=[logits1], outputs=[probs1], attrs={\"axis\": 1}\n",
    "    )\n",
    "    softmax2 = gs.Node(\n",
    "        op=\"Softmax\", inputs=[logits2], outputs=[probs2], attrs={\"axis\": 1}\n",
    "    )\n",
    "\n",
    "    # Average: (probs1 + logits2) / 2\n",
    "\n",
    "    constant_07 = gs.Constant(\n",
    "        name=\"constant_07\", values=np.array(0.5, dtype=np.float32)\n",
    "    )  # Scalar for broadcast\n",
    "    constant_03 = gs.Constant(\n",
    "        name=\"constant_03\", values=np.array(0.5, dtype=np.float32)\n",
    "    )  # Scalar for broadcast\n",
    "    mul1 = gs.Node(\n",
    "        op=\"Mul\",  # Equivalent to / 2\n",
    "        inputs=[probs1, constant_07],\n",
    "        outputs=[avg_output1],\n",
    "    )\n",
    "    mul2 = gs.Node(\n",
    "        op=\"Mul\",  # Equivalent to / 2\n",
    "        inputs=[probs2, constant_03],\n",
    "        outputs=[avg_output2],\n",
    "    )\n",
    "    add = gs.Node(op=\"Add\", inputs=[avg_output1, avg_output2], outputs=[sum_avg])\n",
    "\n",
    "    graph1.cleanup()\n",
    "    graph2.cleanup()\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: avg_output\n",
    "    # We put graph1 nodes first, then graph2 nodes (which we've namespaced) so producers appear before consumers.\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes + graph2.nodes + [softmax1, softmax2, mul1, mul2, add],  #\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[sum_avg],\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export - cleanup will remove unused nodes and should also fix ordering where possible\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# Usage\n",
    "# Note: adjust paths as needed\n",
    "combined = create_combined_onnx(MODEL_PATH_1, MODEL_PATH_2, MODEL_PATH_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c776c",
   "metadata": {},
   "source": [
    "### Create model from only 1 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in ['ReduceL2', 'ReduceMean']:\n",
    "            debug_nodes.append({\n",
    "                'name': node.name,\n",
    "                'op': node.op,\n",
    "                'inputs_count': len(node.inputs),\n",
    "                'inputs_types': [type(inp).__name__ for inp in node.inputs],\n",
    "                'second_input_name': node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "            })\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (c_node.op == 'Constant' and \n",
    "                        c_node.outputs and len(c_node.outputs) == 1 and \n",
    "                        c_node.outputs[0].name == axes_var.name):\n",
    "                        constant_node = c_node\n",
    "                        if 'value' in c_node.attrs:\n",
    "                            axes_values = c_node.attrs['value'].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs['axes'] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if 'keepdims' not in node.attrs:\n",
    "                        node.attrs['keepdims'] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\")\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\")\n",
    "    if debug_nodes:\n",
    "        print(f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\")\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\")\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "# def _rename_graph_tensors_and_nodes(graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None):\n",
    "#     \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "#     This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "#     ensure we don't rename the shared input Variable object.\n",
    "#     \"\"\"\n",
    "#     if skip_vars is None:\n",
    "#         skip_vars = []\n",
    "#     skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "#     # Rename variables (tensors)\n",
    "#     tensors = list(graph.tensors().values())\n",
    "#     for var in tensors:\n",
    "#         if id(var) in skip_ids:\n",
    "#             continue\n",
    "#         if var.name:\n",
    "#             var.name = prefix + var.name\n",
    "\n",
    "#     # Rename nodes\n",
    "#     for node in graph.nodes:\n",
    "#         if node.name:\n",
    "#             node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(model_path1, output_path='combined.onnx'):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one:\n",
    "    - Model1: takes 'image' and 'demographics' -> logits1\n",
    "    - Model2: takes 'image' -> logits2\n",
    "    - Combined: takes 'image' and 'demographics' -> (softmax(logits1) + logits2) / 2\n",
    "\n",
    "    Key changes vs. earlier: we rename the second graph's tensors/nodes with a prefix to avoid name collisions\n",
    "    and ensure the shared `image` input variable object is used by both graphs. This prevents duplicate tensor\n",
    "    names and topological ordering issues during checker validation.\n",
    "        \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    # onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    # graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    # total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Rename for clarity and sharing\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = 'image'\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = 'demographics'\n",
    "\n",
    "    # Grab model2's image input object BEFORE renaming so we can skip renaming that specific Variable\n",
    "    # old_image_input = graph2.inputs[0]\n",
    "    # old_demo_input = graph2.inputs[1]\n",
    "\n",
    "    # Rename graph2 tensors/nodes to avoid clashes (but don't rename the image Variable object)\n",
    "    # _rename_graph_tensors_and_nodes(graph2, prefix='g2_', skip_vars=[old_image_input, old_demo_input])\n",
    "    # _rename_graph_tensors_and_nodes(graph2, prefix='g2_', skip_vars=[old_image_input])\n",
    "\n",
    "    # Replace all references in graph2 nodes from old_image_input to the shared image_input object\n",
    "    # for node in graph2.nodes:\n",
    "    #     for i in range(len(node.inputs)):\n",
    "    #         if node.inputs[i] is old_image_input:\n",
    "    #             node.inputs[i] = image_input\n",
    "            # if node.inputs[i] is old_demo_input:\n",
    "            #     node.inputs[i] = demographics_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared input object (this removes a duplicate input with same name)\n",
    "    # graph2.inputs[0] = image_input\n",
    "    # graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = 'logits1'\n",
    "    \n",
    "    # logits2 = graph2.outputs[0]\n",
    "    # logits2.name = 'logits2'\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    print(orig_shape)\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 11  # Fallback assumption based on reported output size\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 11]  # Fallback\n",
    "        num_classes = 11\n",
    "        print(f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 10]\")\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define output variables WITH dtype and shape (no flattening)\n",
    "    probs1 = gs.Variable('probs1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    # probs2 = gs.Variable('probs2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    sum_avg = gs.Variable('sum_avg', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output = gs.Variable('avg_output', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    # avg_output2 = gs.Variable('avg_output2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "\n",
    "    # Softmax on first model (axis=1 for [batch, classes])\n",
    "\n",
    "    # softmax2 = gs.Node(\n",
    "    #     op='Softmax',\n",
    "    #     inputs=[logits2],\n",
    "    #     outputs=[probs2],\n",
    "    #     attrs={'axis': 1}\n",
    "    # )\n",
    "\n",
    "    # Average: (probs1 + logits2) / 2\n",
    "    rand = random.uniform(1,2)\n",
    "    print(rand)\n",
    "    constant_rand = gs.Constant(name='constant_rand', values=np.array(rand, dtype=np.float32))  # Scalar for broadcast\n",
    "    # constant_03 = gs.Constant(name='constant_03', values=np.array(0.5, dtype=np.float32))  # Scalar for broadcast\n",
    "    mul = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[logits1, constant_rand],\n",
    "        outputs=[avg_output]\n",
    "    )\n",
    "    softmax = gs.Node(\n",
    "        op='Softmax',\n",
    "        inputs=[avg_output],\n",
    "        outputs=[probs1],\n",
    "        attrs={'axis': 1}\n",
    "    )    \n",
    "    # mul2 = gs.Node(\n",
    "    #     op='Mul',  # Equivalent to / 2\n",
    "    #     inputs=[probs2, constant_03],\n",
    "    #     outputs=[avg_output2]\n",
    "    # )\n",
    "    # add = gs.Node(\n",
    "    #     op='Add',\n",
    "    #     inputs=[avg_output1, avg_output2],\n",
    "    #     outputs=[sum_avg]\n",
    "    # )\n",
    "\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: avg_output\n",
    "    # We put graph1 nodes first, then graph2 nodes (which we've namespaced) so producers appear before consumers.\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes + [mul, softmax],\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[probs1]\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export - cleanup will remove unused nodes and should also fix ordering where possible\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "# Usage\n",
    "# Note: adjust paths as needed\n",
    "combined = create_combined_onnx(MODEL_PATH_1, MODEL_PATH_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e22908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the original model\n",
    "model = onnx.load(\"model/tricorder-3/30_new.onnx\")\n",
    "\n",
    "# Check original details (optional: for debugging)\n",
    "print(\"Original IR version:\", model.ir_version)\n",
    "print(\"Original opset versions:\", [(imp.domain, imp.version) for imp in model.opset_import])\n",
    "\n",
    "# Downgrade IR version to 11 (your runtime's max)\n",
    "model.ir_version = 10\n",
    "\n",
    "# Save the downgraded model\n",
    "downgraded_path = \"model/tricorder-3/30_new.onnx\"\n",
    "onnx.save(model, downgraded_path)\n",
    "print(f\"Downgraded model saved to: {downgraded_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3136b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
