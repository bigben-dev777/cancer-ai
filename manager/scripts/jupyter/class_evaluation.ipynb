{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a38fb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86773f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def log_to_file(path: str, data: Any) -> None:\n",
    "    \"\"\"\n",
    "    Automatically write or append Python data to a JSON file.\n",
    "\n",
    "    - If the file doesn't exist â†’ create and write.\n",
    "    - If the file exists:\n",
    "        - If it contains a JSON list â†’ append to the list.\n",
    "        - If it contains a single object â†’ convert to a list and append.\n",
    "    \"\"\"\n",
    "    file_path = Path(path)\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        if file_path.exists():\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                try:\n",
    "                    existing = json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    existing = []\n",
    "\n",
    "            # Ensure existing data is a list\n",
    "            if not isinstance(existing, list):\n",
    "                existing = [existing]\n",
    "\n",
    "            existing.append(data)\n",
    "\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(existing, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            print(f\"âœ… Data appended to {file_path}\")\n",
    "        else:\n",
    "            # File doesn't exist â†’ create and write\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            print(f\"âœ… Data written to new file {file_path}\")\n",
    "\n",
    "    except TypeError as e:\n",
    "        print(f\"âŒ Data is not JSON serializable: {e}\")\n",
    "    except IOError as e:\n",
    "        print(f\"âŒ File error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0db3c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\n",
    "    \"AKIEC\",\n",
    "    \"BCC\",\n",
    "    \"BEN_OTH\",\n",
    "    \"BKL\",\n",
    "    \"DF\",\n",
    "    \"INF\",\n",
    "    \"MAL_OTH\",\n",
    "    \"MEL\",\n",
    "    \"NV\",\n",
    "    \"SCCKA\",\n",
    "    \"VASC\",\n",
    "]\n",
    "\n",
    "base_img_dir = \"../../dataset\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8b4aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONNXInference:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize ONNX model session.\"\"\"\n",
    "        self.session = ort.InferenceSession(model_path)\n",
    "        self.input_names = [inp.name for inp in self.session.get_inputs()]\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess image to [0,1] and BCHW format.\"\"\"\n",
    "        img = Image.open(base_img_dir + \"/\" + image_path).convert(\"RGB\")\n",
    "        img = img.resize((512, 512))\n",
    "        img_array = np.array(img, dtype=np.float32) / 255.0  # scale to [0,1]\n",
    "        img_array = np.transpose(img_array, (2, 0, 1))  # HWC -> CHW\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
    "        return img_array\n",
    "\n",
    "    def predict(self, image_path, age, gender, location):\n",
    "        \"\"\"Run inference on a single image with demographic data.\"\"\"\n",
    "        # print(f'ðŸ–¼ï¸ image path {image_path}')\n",
    "        image_tensor = self.preprocess_image(image_path)\n",
    "        gender_encoded = 1.0 if gender.lower() == \"m\" else 0.0\n",
    "        demo_tensor = np.array(\n",
    "            [[float(age), gender_encoded, float(location)]], dtype=np.float32\n",
    "        )\n",
    "        if len(self.input_names) >= 2:\n",
    "            inputs = {\n",
    "                self.input_names[0]: image_tensor,\n",
    "                self.input_names[1]: demo_tensor,\n",
    "            }\n",
    "        else:\n",
    "            inputs = {self.input_names[0]: image_tensor}\n",
    "        outputs = self.session.run(None, inputs)\n",
    "        probs = outputs[0].flatten()\n",
    "        pred = np.argmax(probs)\n",
    "        return probs, pred, CLASS_NAMES[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd35199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found models: ['../../models/2025-11-27/speechmaster/18_model118.onnx', '../../models/2025-11-27/speechmaster/62_model94.onnx', '../../models/2025-11-27/yolo_skin_11.onnx']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# df = pd.read_csv(\"../../dataset/data.csv\")\n",
    "df = pd.read_csv(\"../../dataset/data.csv\")\n",
    "le = LabelEncoder()\n",
    "df[\"Location\"] = le.fit_transform(df[\"Location\"])\n",
    "# Find all ONNX models\n",
    "model_folder = \"../../models/2025-11-27\"\n",
    "model_paths = []\n",
    "# model_paths = [\n",
    "#     \"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "#     \"../../models/2025-11-27/speechmaster/62_model94.onnx\",\n",
    "#     \"../../models/2025-11-27/speechmaster/122_model123.onnx\",\n",
    "#     \"../../models/combine/2025-11-27/18vs62_down.onnx\",\n",
    "#     \"../../models/combine/2025-11-27/18vs122_down.onnx\",\n",
    "# ]\n",
    "# model_paths = glob.glob(os.path.join(model_folder, \"**\", \"*.onnx\"), recursive=True)\n",
    "\n",
    "model_paths.append(\"../../models/2025-11-27/speechmaster/18_model118.onnx\")\n",
    "model_paths.append(\"../../models/2025-11-27/speechmaster/62_model94.onnx\")\n",
    "\n",
    "print(\"Found models:\", model_paths)\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "prediction_result = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02519be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 18_model118.onnx: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:51<00:00,  7.72it/s]\n",
      "Processing 62_model94.onnx: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:53<00:00,  7.44it/s]\n",
      "Processing yolo_skin_11.onnx: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [01:02<00:00,  6.43it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_path in model_paths:\n",
    "    onnx_model = ONNXInference(model_path=model_path)\n",
    "    model_result = {cls: 0 for cls in CLASS_NAMES}\n",
    "\n",
    "    res_list = []\n",
    "\n",
    "    #select specific class\n",
    "    df_test = df.copy()\n",
    "    # df_test = df[df['Class'] == \"MEL\"]\n",
    "    # Inner loop wrapped with tqdm for progress\n",
    "    for _, row in tqdm(\n",
    "        df_test.iterrows(), total=len(df_test), desc=f\"Processing {model_path.split('/')[-1]}\"\n",
    "    ):\n",
    "        cell = {}\n",
    "        probs, pred, cls = onnx_model.predict(\n",
    "            row[\"NewFileName\"], row[\"Age\"], row[\"Gender\"], row[\"Location\"]\n",
    "        )\n",
    "        cell[\"probs\"] = probs\n",
    "        cell[\"pred\"] = pred\n",
    "        cell[\"cls\"] = cls\n",
    "        if row[\"Class\"] in cls:\n",
    "            model_result[row[\"Class\"]] += 1\n",
    "        res_list.append(cell)\n",
    "\n",
    "    results[model_path] = model_result\n",
    "    prediction_result[model_path] = res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac310c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "BCC        2522\n",
       "NV          729\n",
       "BKL         544\n",
       "SCCKA       473\n",
       "MEL         450\n",
       "AKIEC       303\n",
       "DF           52\n",
       "INF          50\n",
       "VASC         45\n",
       "BEN_OTH      43\n",
       "MAL_OTH       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59cb22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path, res in results.items():\n",
    "    print(model_path, res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "519db990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data appended to ../../logs/prediction_summary.log\n",
      "âœ… Data appended to ../../logs/prediction_list.log\n"
     ]
    }
   ],
   "source": [
    "log_to_file(\"../../logs/prediction_summary.log\", results)\n",
    "log_to_file(\"../../logs/prediction_list.log\", prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c36722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46a5eb7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(results\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m counts_per_class \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classes = list(next(iter(results.values())).keys())\n",
    "models = list(results.keys())\n",
    "\n",
    "counts_per_class = df[\"Class\"].value_counts().to_dict()\n",
    "\n",
    "for cls in classes:\n",
    "    try:\n",
    "        counts = [results[model][cls] for model in models]\n",
    "        percents = [results[model][cls] / counts_per_class.get(cls, 1) for model in models]\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        bars = plt.barh(\n",
    "            [model.split(\"/\")[-1] for model in models], percents, color=\"skyblue\"\n",
    "        )\n",
    "\n",
    "        # Add count labels on each bar\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            plt.text(\n",
    "                width + 0.01,\n",
    "                bar.get_y() + bar.get_height() / 2,\n",
    "                str(int(width * counts_per_class[cls]) ),\n",
    "                va=\"center\",\n",
    "                ha=\"left\",\n",
    "            )\n",
    "\n",
    "        plt.xlabel(f\"Total Count {counts_per_class[cls]}\")\n",
    "        plt.ylabel(\"Models\")\n",
    "        plt.xlim(0,1)\n",
    "        plt.title(f\"Counts of class '{cls}' per model\")\n",
    "        # plt.tight_layout()\n",
    "        plt.show()\n",
    "    except:\n",
    "        print('This class is not there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85414ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
