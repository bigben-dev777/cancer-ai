{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fcd9fe3",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fca0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASE_DIR = \"/home/mateo/cancer-ai/manager/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af0f7d",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eeac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(folder_path):\n",
    "    import os\n",
    "\n",
    "    # List to store ONNX model paths\n",
    "    onnx_models = []\n",
    "\n",
    "    # Loop through the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".onnx\"):\n",
    "            onnx_models.append(os.path.join(folder_path, file_name))\n",
    "\n",
    "    return onnx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037780c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights\n",
    "import onnxruntime as ort\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "whitelist1 = [0, 3, 10]  # Example: classes for model1\n",
    "whitelist2 = [1, 2, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "class OnnxCombineModel(nn.Module):\n",
    "    def __init__(self, model_path1, model_path2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.session1 = ort.InferenceSession(model_path1)\n",
    "        self.session2 = ort.InferenceSession(model_path2)\n",
    "        self.input_names1 = [inp.name for inp in self.session1.get_inputs()]\n",
    "        self.input_names2 = [inp.name for inp in self.session2.get_inputs()]\n",
    "\n",
    "    def forward(self, image, demographics):\n",
    "        print(\"|\" * 60)\n",
    "        print(self.input_names1)\n",
    "        print(self.input_names2)\n",
    "        inputs1 = {self.input_names1[0]: image, self.input_names1[1]: demographics}\n",
    "        # inputs2 = {self.input_names2[0]: image} ### 43  84 model ###\n",
    "        inputs2 = {\n",
    "            self.input_names2[0]: image,\n",
    "            self.input_names2[1]: demographics,\n",
    "        }  ### 108 grose model ###\n",
    "\n",
    "        outputs1 = self.session1.run(None, inputs1)\n",
    "        outputs2 = self.session2.run(None, inputs2)\n",
    "\n",
    "        probs1 = outputs1[0].flatten()\n",
    "        idx = np.argmax(probs1)\n",
    "\n",
    "        if idx in whitelist1:\n",
    "            print('ðŸ”´','model1')\n",
    "            return F.softmax(torch.tensor(probs1 * 3), dim=0)\n",
    "\n",
    "        probs2 = outputs2[0].flatten()  ### 43 84 model ###\n",
    "        idx = np.argmax(probs2)\n",
    "        if idx in whitelist2:\n",
    "            print('ðŸ”´','model2')\n",
    "            return F.softmax(torch.tensor(probs2 * 3), dim=0)\n",
    "\n",
    "        probs = probs1 * 0.5 + 0.5 * probs2\n",
    "        probs = probs * 3\n",
    "        return F.softmax(torch.tensor(probs), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d25d80",
   "metadata": {},
   "source": [
    "Test Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a43e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "model = OnnxCombineModel(\n",
    "    \"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "    \"../../models/2025-11-27/speechmaster/62_model94.onnx\",\n",
    ")\n",
    "device = \"cpu\"\n",
    "image = Image.open(\n",
    "    f\"../../dataset/dataset00016/0a605167-4e6e-4104-bc06-1aee2e71b33b.jpg\"\n",
    ").convert(\"RGB\")\n",
    "image = image.resize((512, 512))\n",
    "image = np.array(image, dtype=np.float32)\n",
    "image = image * (1.0 / 255.0)\n",
    "\n",
    "image = np.transpose(image, (2, 0, 1))\n",
    "image = torch.from_numpy(image).to(device)\n",
    "image = image.unsqueeze(0)\n",
    "# print(image.shape)\n",
    "data = torch.tensor([30, 0, 6], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "image = image.numpy()\n",
    "data = data.numpy()\n",
    "result = model(image, data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284374d4",
   "metadata": {},
   "source": [
    "Test Onnx Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef966cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"Actinic keratosis (AK)\",\n",
    "    \"Basal cell carcinoma (BCC)\",\n",
    "    \"Seborrheic keratosis (SK)\",\n",
    "    \"Squamous cell carcinoma (SCC)\",\n",
    "    \"Vascular lesion (VASC)\",\n",
    "    \"Dermatofibroma (DF)\",\n",
    "    \"Benign nevus (NV)\",\n",
    "    \"Other non-neoplastic (NON)\",\n",
    "    \"Melanoma (MEL)\",\n",
    "    \"Other neoplastic (ON)\",\n",
    "]\n",
    "\n",
    "\n",
    "class ONNXInference:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize ONNX model session.\"\"\"\n",
    "\n",
    "        self.session = ort.InferenceSession(model_path)\n",
    "        self.input_names = [inp.name for inp in self.session.get_inputs()]\n",
    "\n",
    "        # Image preprocessing\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((512, 512)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess image to [0,512] range as specified.\"\"\"\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        # Resize to 512x512\n",
    "        img = img.resize((512, 512))\n",
    "        # Convert to numpy array with [0,512] range\n",
    "        img_array = np.array(img, dtype=np.float32)\n",
    "        # Scale from [0,255] to [0,512]\n",
    "        img_array = img_array * (1 / 255.0)\n",
    "        # Convert to BCHW format\n",
    "        img_array = np.transpose(img_array, (2, 0, 1))\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        return img_array\n",
    "\n",
    "    def predict(self, image_path, age, gender, location):\n",
    "        \"\"\"Run inference on a single image with demographic data.\"\"\"\n",
    "        # Preprocess image\n",
    "        image_tensor = self.preprocess_image(image_path)\n",
    "\n",
    "        # Convert demographics to proper format\n",
    "        # Gender: 'm' -> 1.0, 'f' -> 0.0\n",
    "        gender_encoded = 1.0 if gender.lower() == \"m\" else 0.0\n",
    "\n",
    "        # Prepare demographic data as [age, gender_encoded, location]\n",
    "        demo_tensor = np.array(\n",
    "            [[float(age), gender_encoded, float(location)]], dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Run inference\n",
    "        inputs = {self.input_names[0]: image_tensor, self.input_names[1]: demo_tensor}\n",
    "        # inputs = {self.input_names[0]: image_tensor}\n",
    "\n",
    "        # inputs = {self.input_names[0]: image_tensor}\n",
    "        outputs = self.session.run(None, inputs)\n",
    "        print(outputs)\n",
    "        # Model already outputs probabilities (softmax applied in forward pass)\n",
    "        probs = outputs[0].flatten()\n",
    "\n",
    "        # Get top 3 predictions\n",
    "        top3_idx = np.argsort(probs)[-3:][::-1]\n",
    "        top3 = [(CLASS_NAMES[i], float(probs[i])) for i in top3_idx]\n",
    "\n",
    "        return top3\n",
    "\n",
    "\n",
    "print(\"----------------\")\n",
    "# ort.InferenceSession(\"onnx/combined-2.onnx\")\n",
    "onnx_model = ONNXInference(\"../../models/combine/2025-11-27/18vs62_1_down.onnx\")\n",
    "# onnx_model = ONNXInference(\"model/84.onnx\")\n",
    "predictions = onnx_model.predict(\n",
    "    f\"../../dataset/dataset00016/0a605167-4e6e-4104-bc06-1aee2e71b33b.jpg\", 30, \"f\", 6\n",
    ")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0db8d5",
   "metadata": {},
   "source": [
    "## Softmax first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a825e",
   "metadata": {},
   "source": [
    "### Combining 36 vs 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c720fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in ['ReduceL2', 'ReduceMean']:\n",
    "            debug_nodes.append({\n",
    "                'name': node.name,\n",
    "                'op': node.op,\n",
    "                'inputs_count': len(node.inputs),\n",
    "                'inputs_types': [type(inp).__name__ for inp in node.inputs],\n",
    "                'second_input_name': node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "            })\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (c_node.op == 'Constant' and \n",
    "                        c_node.outputs and len(c_node.outputs) == 1 and \n",
    "                        c_node.outputs[0].name == axes_var.name):\n",
    "                        constant_node = c_node\n",
    "                        if 'value' in c_node.attrs:\n",
    "                            axes_values = c_node.attrs['value'].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs['axes'] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if 'keepdims' not in node.attrs:\n",
    "                        node.attrs['keepdims'] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\")\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\")\n",
    "    if debug_nodes:\n",
    "        print(f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\")\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\")\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "def create_combined_onnx(model_path1, model_path2, output_path='combined.onnx'):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one:\n",
    "    - Model1: takes 'image' and 'demographics' -> logits1\n",
    "    - Model2: takes 'image' -> logits2\n",
    "    - Combined: takes 'image' and 'demographics' -> (softmax(logits1) + logits2) / 2\n",
    "    \n",
    "    Note: This averages probabilities from Model1 with raw logits from Model2, which may not be semantically ideal\n",
    "    due to scale differences (probabilities in [0,1], logits unbounded). Consider if softmax should also be applied\n",
    "    to Model2 or if the final average should be softmaxed.\n",
    "    \n",
    "    Assumes:\n",
    "    - Both models output a single tensor of shape [batch_size, num_classes] (logits).\n",
    "    - Input names: Model1 has two inputs (first: image, second: demographics); Model2 has one (image).\n",
    "    - You need to pip install onnx onnx-graphsurgeon if not already installed.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "    \n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "    \n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "    \n",
    "    # Assume input names and order based on your code\n",
    "    # Rename for clarity and sharing\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = 'image'\n",
    "    \n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = 'demographics'\n",
    "    \n",
    "    # Share the image input with model2\n",
    "    old_image_input = graph2.inputs[0]\n",
    "    shared_image_input = image_input  # Shared reference, named 'image'\n",
    "    \n",
    "    # Replace all references in graph2 nodes from old_image_input to shared_image_input\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = shared_image_input\n",
    "    \n",
    "    # Update graph2's inputs list to use the shared input\n",
    "    graph2.inputs[0] = shared_image_input\n",
    "    \n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = 'logits1'\n",
    "    \n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = 'logits2'\n",
    "    \n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 10  # Fallback assumption based on reported output size\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 10]  # Fallback\n",
    "        num_classes = 10\n",
    "        print(f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 10]\")\n",
    "    \n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "    \n",
    "    # Define output variables WITH dtype and shape (no flattening)\n",
    "    probs1 = gs.Variable('probs1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    sum_avg = gs.Variable('sum_avg', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output = gs.Variable('avg_output', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output1 = gs.Variable('avg_output1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output2 = gs.Variable('avg_output2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    \n",
    "    # Softmax on first model (axis=1 for [batch, classes])\n",
    "    softmax1 = gs.Node(\n",
    "        op='Softmax',\n",
    "        inputs=[logits1],\n",
    "        outputs=[probs1],\n",
    "        attrs={'axis': 1}\n",
    "    )\n",
    "    \n",
    "    # Average: (probs1 + logits2) / 2\n",
    "\n",
    "    \n",
    "    constant_07 = gs.Constant(name='constant_07', values=np.array(0.4, dtype=np.float32))  # Scalar for broadcast\n",
    "    constant_03 = gs.Constant(name='constant_03', values=np.array(0.6, dtype=np.float32))  # Scalar for broadcast\n",
    "    mul1 = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[probs1, constant_07],\n",
    "        outputs=[avg_output1]\n",
    "    )\n",
    "    mul2 = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[logits2, constant_03],\n",
    "        outputs=[avg_output2]\n",
    "    )\n",
    "    \n",
    "    add = gs.Node(\n",
    "        op='Add',\n",
    "        inputs=[avg_output1, avg_output2],\n",
    "        outputs=[sum_avg]\n",
    "    )\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: avg_output\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes + graph2.nodes + [softmax1, mul1, mul2, add],\n",
    "        inputs=[shared_image_input, demographics_input],\n",
    "        outputs=[sum_avg]\n",
    "    )\n",
    "    \n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "    \n",
    "    # Cleanup and export\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "    \n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "    \n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "    \n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "    \n",
    "    return combined_model\n",
    "\n",
    "# Usage\n",
    "combined = create_combined_onnx('model/36.onnx', 'model/43_modelvip.onnx', \"model/test(7.3).onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cc8a3",
   "metadata": {},
   "source": [
    "### Combining 36 vs 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in ['ReduceL2', 'ReduceMean']:\n",
    "            debug_nodes.append({\n",
    "                'name': node.name,\n",
    "                'op': node.op,\n",
    "                'inputs_count': len(node.inputs),\n",
    "                'inputs_types': [type(inp).__name__ for inp in node.inputs],\n",
    "                'second_input_name': node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "            })\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (c_node.op == 'Constant' and \n",
    "                        c_node.outputs and len(c_node.outputs) == 1 and \n",
    "                        c_node.outputs[0].name == axes_var.name):\n",
    "                        constant_node = c_node\n",
    "                        if 'value' in c_node.attrs:\n",
    "                            axes_values = c_node.attrs['value'].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs['axes'] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if 'keepdims' not in node.attrs:\n",
    "                        node.attrs['keepdims'] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\")\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\")\n",
    "    if debug_nodes:\n",
    "        print(f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\")\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\")\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename the shared input Variable object.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    tensors = list(graph.tensors().values())\n",
    "    for var in tensors:\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(model_path1, model_path2, output_path='combined.onnx'):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one:\n",
    "    - Model1: takes 'image' and 'demographics' -> logits1\n",
    "    - Model2: takes 'image' -> logits2\n",
    "    - Combined: takes 'image' and 'demographics' -> (softmax(logits1) + logits2) / 2\n",
    "\n",
    "    Key changes vs. earlier: we rename the second graph's tensors/nodes with a prefix to avoid name collisions\n",
    "    and ensure the shared `image` input variable object is used by both graphs. This prevents duplicate tensor\n",
    "    names and topological ordering issues during checker validation.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Rename for clarity and sharing\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = 'image'\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = 'demographics'\n",
    "\n",
    "    # Grab model2's image input object BEFORE renaming so we can skip renaming that specific Variable\n",
    "    old_image_input = graph2.inputs[0]\n",
    "\n",
    "    # Rename graph2 tensors/nodes to avoid clashes (but don't rename the image Variable object)\n",
    "    _rename_graph_tensors_and_nodes(graph2, prefix='g2_', skip_vars=[old_image_input])\n",
    "\n",
    "    # Replace all references in graph2 nodes from old_image_input to the shared image_input object\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = image_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared input object (this removes a duplicate input with same name)\n",
    "    graph2.inputs[0] = image_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = 'logits1'\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = 'logits2'\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 10  # Fallback assumption based on reported output size\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 10]  # Fallback\n",
    "        num_classes = 10\n",
    "        print(f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 10]\")\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define output variables WITH dtype and shape (no flattening)\n",
    "    probs1 = gs.Variable('probs1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    probs2 = gs.Variable('probs2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    sum_avg = gs.Variable('sum_avg', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output1 = gs.Variable('avg_output1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output2 = gs.Variable('avg_output2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "\n",
    "    # Softmax on first model (axis=1 for [batch, classes])\n",
    "    softmax1 = gs.Node(\n",
    "        op='Softmax',\n",
    "        inputs=[logits1],\n",
    "        outputs=[probs1],\n",
    "        attrs={'axis': 1}\n",
    "    )    \n",
    "    softmax2 = gs.Node(\n",
    "        op='Softmax',\n",
    "        inputs=[logits2],\n",
    "        outputs=[probs2],\n",
    "        attrs={'axis': 1}\n",
    "    )\n",
    "\n",
    "    # Average: (probs1 + logits2) / 2\n",
    "\n",
    "    constant_07 = gs.Constant(name='constant_07', values=np.array(0.7, dtype=np.float32))  # Scalar for broadcast\n",
    "    constant_03 = gs.Constant(name='constant_03', values=np.array(0.3, dtype=np.float32))  # Scalar for broadcast\n",
    "    mul1 = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[probs1, constant_03],\n",
    "        outputs=[avg_output1]\n",
    "    )\n",
    "    mul2 = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[probs2, constant_07],\n",
    "        outputs=[avg_output2]\n",
    "    )\n",
    "    add = gs.Node(\n",
    "        op='Add',\n",
    "        inputs=[avg_output1, avg_output2],\n",
    "        outputs=[sum_avg]\n",
    "    )\n",
    "\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: avg_output\n",
    "    # We put graph1 nodes first, then graph2 nodes (which we've namespaced) so producers appear before consumers.\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes + graph2.nodes + [softmax1, softmax2, mul1, mul2, add],\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[sum_avg]\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export - cleanup will remove unused nodes and should also fix ordering where possible\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# Usage\n",
    "# Note: adjust paths as needed\n",
    "combined = create_combined_onnx('model/36.onnx', 'model/84.onnx', \"model/softmax_36_84(3.7).onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3e7ad",
   "metadata": {},
   "source": [
    "### Combining 36 vs 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "import uuid\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in ['ReduceL2', 'ReduceMean']:\n",
    "            debug_nodes.append({\n",
    "                'name': node.name,\n",
    "                'op': node.op,\n",
    "                'inputs_count': len(node.inputs),\n",
    "                'inputs_types': [type(inp).__name__ for inp in node.inputs],\n",
    "                'second_input_name': node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "            })\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (c_node.op == 'Constant' and \n",
    "                        c_node.outputs and len(c_node.outputs) == 1 and \n",
    "                        c_node.outputs[0].name == axes_var.name):\n",
    "                        constant_node = c_node\n",
    "                        if 'value' in c_node.attrs:\n",
    "                            axes_values = c_node.attrs['value'].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs['axes'] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if 'keepdims' not in node.attrs:\n",
    "                        node.attrs['keepdims'] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\")\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\")\n",
    "    if debug_nodes:\n",
    "        print(f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\")\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\")\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename shared input Variable objects.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    for var in list(graph.tensors().values()):\n",
    "        # skip renaming the exact variable objects that are shared\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(model_path1, model_path2, output_path='combined.onnx'):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one:\n",
    "    - Model1: takes 'image' and 'demographics' -> logits1\n",
    "    - Model2: takes 'image' -> logits2\n",
    "    - Combined: takes 'image' and 'demographics' -> average(softmax(logits1), softmax(logits2))\n",
    "\n",
    "    Approach:\n",
    "    - Import both graphs with onnx-graphsurgeon\n",
    "    - Capture model2's original input Variable objects (so we can find & replace them)\n",
    "    - Namespace (prefix) all graph2 tensors/nodes to avoid collisions, except the original model2 input Variable objects\n",
    "    - Replace model2's input references with the shared input Variable objects from graph1\n",
    "    - Build combined graph with graph1 nodes first, then graph2 nodes, then the new ops\n",
    "    - Cleanup, infer shapes, and run checker\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Prepare shared inputs from graph1\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = 'image'\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = 'demographics'\n",
    "\n",
    "    # Save model2's original input variable objects so we can target them for replacement\n",
    "    model2_image_var = graph2.inputs[0]\n",
    "    model2_demo_var = None\n",
    "    if len(graph2.inputs) > 1:\n",
    "        model2_demo_var = graph2.inputs[1]\n",
    "\n",
    "    # Namespace graph2 to avoid collisions but skip the original input objects\n",
    "    prefix = 'g2_'\n",
    "    _rename_graph_tensors_and_nodes(graph2, prefix=prefix, skip_vars=[model2_image_var] + ([model2_demo_var] if model2_demo_var is not None else []))\n",
    "\n",
    "    # Replace references in graph2 nodes from the original model2 input objects to the shared ones\n",
    "    for node in graph2.nodes:\n",
    "        for i, inp in enumerate(node.inputs):\n",
    "            if inp is model2_image_var:\n",
    "                node.inputs[i] = image_input\n",
    "            elif model2_demo_var is not None and inp is model2_demo_var:\n",
    "                node.inputs[i] = demographics_input\n",
    "\n",
    "    # Now update graph2's inputs list to use the shared input objects\n",
    "    graph2.inputs[0] = image_input\n",
    "    if model2_demo_var is not None:\n",
    "        # If model2 had a demographics input, map it to the shared demographics\n",
    "        graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = 'logits1'\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    # The logits2 variable object may have been renamed (prefixed), ensure we use the object itself\n",
    "    logits2.name = 'logits2'\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 10  # Fallback assumption based on reported output size\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 10]  # Fallback\n",
    "        num_classes = 10\n",
    "        print(f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 10]\")\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Create variables for intermediate and final tensors\n",
    "    probs1 = gs.Variable('probs1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    probs2 = gs.Variable('probs2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg1 = gs.Variable('avg1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg2 = gs.Variable('avg2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    final_avg = gs.Variable('final_avg', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "\n",
    "    # Softmax on both logits (axis=1)\n",
    "    softmax1 = gs.Node(op='Softmax', inputs=[logits1], outputs=[probs1], attrs={'axis': 1})\n",
    "    softmax2 = gs.Node(op='Softmax', inputs=[logits2], outputs=[probs2], attrs={'axis': 1})\n",
    "\n",
    "    # Multiply each probability vector by 0.5 (use uniquely named constant to avoid duplication)\n",
    "    constant_07 = gs.Constant(name='constant_07', values=np.array(0.7, dtype=np.float32))  # Scalar for broadcast\n",
    "    constant_03 = gs.Constant(name='constant_03', values=np.array(0.3, dtype=np.float32))  # Scalar for broadcast\n",
    "\n",
    "    mul1 = gs.Node(op='Mul', inputs=[probs1, constant_07], outputs=[avg1])\n",
    "    mul2 = gs.Node(op='Mul', inputs=[probs2, constant_03], outputs=[avg2])\n",
    "\n",
    "    # Add the two halves to get the average\n",
    "    add = gs.Node(op='Add', inputs=[avg1, avg2], outputs=[final_avg])\n",
    "\n",
    "    # Build combined graph\n",
    "    # Place graph1 nodes first, then graph2 nodes (namespaced), then our fusion nodes\n",
    "    combined_nodes = list(graph1.nodes) + list(graph2.nodes) + [softmax1, softmax2, mul1, mul2, add]\n",
    "\n",
    "    combined_graph = gs.Graph(nodes=combined_nodes, inputs=[image_input, demographics_input], outputs=[final_avg])\n",
    "\n",
    "    # Set a reasonable opset\n",
    "    combined_graph.opset = max(getattr(graph1, 'opset', 11), getattr(graph2, 'opset', 11), 11)\n",
    "\n",
    "    # Cleanup and export\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Validate\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# Usage example (adjust paths as needed)\n",
    "combined = create_combined_onnx('model/36.onnx', 'model/108_grose.onnx', \"model/softmax_36_108(7.3).onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ae754",
   "metadata": {},
   "source": [
    "### Combining 18 vs 62"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff70295",
   "metadata": {},
   "source": [
    "#### Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4c288f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model1] Total ReduceMean nodes: 32, Fixed: 0\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.1/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.1/blocks.1.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  ... and 29 more\n",
      "[Model2] Total ReduceMean nodes: 34, Fixed: 0\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.1/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.1/blocks.1.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  ... and 31 more\n",
      "No reduction fixes applied - check debug output above\n",
      "Inferred output shape: [None, 11]\n",
      "Combined ONNX model saved to ../../models/combine/2025-11-27/62vs18.onnx\n",
      "Output shape: [None, 11]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in [\"ReduceL2\", \"ReduceMean\"]:\n",
    "            debug_nodes.append(\n",
    "                {\n",
    "                    \"name\": node.name,\n",
    "                    \"op\": node.op,\n",
    "                    \"inputs_count\": len(node.inputs),\n",
    "                    \"inputs_types\": [type(inp).__name__ for inp in node.inputs],\n",
    "                    \"second_input_name\": (\n",
    "                        node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (\n",
    "                        c_node.op == \"Constant\"\n",
    "                        and c_node.outputs\n",
    "                        and len(c_node.outputs) == 1\n",
    "                        and c_node.outputs[0].name == axes_var.name\n",
    "                    ):\n",
    "                        constant_node = c_node\n",
    "                        if \"value\" in c_node.attrs:\n",
    "                            axes_values = c_node.attrs[\"value\"].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs[\"axes\"] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if \"keepdims\" not in node.attrs:\n",
    "                        node.attrs[\"keepdims\"] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\"\n",
    "                    )\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\"\n",
    "                    )\n",
    "    if debug_nodes:\n",
    "        print(\n",
    "            f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\"\n",
    "        )\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(\n",
    "                f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\"\n",
    "            )\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(\n",
    "    graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None\n",
    "):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename the shared input Variable object.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    tensors = list(graph.tensors().values())\n",
    "    for var in tensors:\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(\n",
    "    model_path1,\n",
    "    model_path2,\n",
    "    whitelist1: List[int],\n",
    "    whitelist2: List[int],\n",
    "    scale_const: float = 3.0,\n",
    "    output_path=\"combined.onnx\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one with conditional logic based on whitelists for skin cancer strategy:\n",
    "    - Compute logits1 from model1.\n",
    "    - If argmax(logits1) in whitelist1, use logits1.\n",
    "    - Else compute logits2 from model2.\n",
    "    - If argmax(logits2) in whitelist2, use logits2.\n",
    "    - Else use average of logits1 and logits2.\n",
    "    - Then scale the chosen logits by scale_const and apply softmax for output.\n",
    "\n",
    "    Assumes:\n",
    "    - Both models take 'image' and 'demographics' as inputs.\n",
    "    - Both output a single tensor of shape [batch_size, num_classes] (logits).\n",
    "    - Whitelists are lists of class indices (integers).\n",
    "    - You need to pip install onnx onnx-graphsurgeon if not already installed.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Assume input names and order based on your code\n",
    "    # Rename for clarity\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = \"image\"\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = \"demographics\"\n",
    "\n",
    "    # Share the inputs with model2\n",
    "    old_image_input = graph2.inputs[0]\n",
    "    old_demo_input = graph2.inputs[1]\n",
    "\n",
    "    _rename_graph_tensors_and_nodes(\n",
    "        graph2, prefix=\"g2_\", skip_vars=[old_image_input, old_demo_input]\n",
    "    )\n",
    "\n",
    "    # Replace all references in graph2 nodes to use shared inputs\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = image_input\n",
    "            if node.inputs[i] is old_demo_input:\n",
    "                node.inputs[i] = demographics_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared inputs\n",
    "    graph2.inputs[0] = image_input\n",
    "    graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = \"logits1\"\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = \"logits2\"\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 11  # Fallback assumption\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 11]  # Fallback\n",
    "        num_classes = 11\n",
    "        print(\n",
    "            f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 11]\"\n",
    "        )\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define variables\n",
    "    class1 = gs.Variable(\"class1\", shape=[None], dtype=np.int64)\n",
    "    class1_unsq = gs.Variable(\"class1_unsq\", shape=[None, 1], dtype=np.int64)\n",
    "    eq1 = gs.Variable(\"eq1\", shape=[None, len(whitelist1)], dtype=np.bool)\n",
    "    cast1 = gs.Variable(\"cast1\", shape=[None, len(whitelist1)], dtype=np.float32)\n",
    "    reduce1 = gs.Variable(\"reduce1\", shape=[None, 1], dtype=np.float32)\n",
    "    is_in1 = gs.Variable(\"is_in1\", shape=[None, 1], dtype=np.bool)\n",
    "    is_in1_exp = gs.Variable(\"is_in1_exp\", shape=output_shape, dtype=np.bool)\n",
    "\n",
    "    class2 = gs.Variable(\"class2\", shape=[None], dtype=np.int64)\n",
    "    class2_unsq = gs.Variable(\"class2_unsq\", shape=[None, 1], dtype=np.int64)\n",
    "    eq2 = gs.Variable(\"eq2\", shape=[None, len(whitelist2)], dtype=np.bool)\n",
    "    cast2 = gs.Variable(\"cast2\", shape=[None, len(whitelist2)], dtype=np.float32)\n",
    "    reduce2 = gs.Variable(\"reduce2\", shape=[None, 1], dtype=np.float32)\n",
    "    is_in2 = gs.Variable(\"is_in2\", shape=[None, 1], dtype=np.bool)\n",
    "    is_in2_exp = gs.Variable(\"is_in2_exp\", shape=output_shape, dtype=np.bool)\n",
    "\n",
    "    logits_shape_var = gs.Variable(\"logits_shape\", dtype=np.int64, shape=[2])\n",
    "\n",
    "    add_output = gs.Variable(\"add_output\", shape=output_shape, dtype=np.float32)\n",
    "    avg_logits = gs.Variable(\"avg_logits\", shape=output_shape, dtype=np.float32)\n",
    "    inner_selected = gs.Variable(\"inner_selected\", shape=output_shape, dtype=np.float32)\n",
    "    selected_logits = gs.Variable(\n",
    "        \"selected_logits\", shape=output_shape, dtype=np.float32\n",
    "    )\n",
    "    scaled_logits = gs.Variable(\"scaled_logits\", shape=output_shape, dtype=np.float32)\n",
    "    final_output = gs.Variable(\"final_output\", shape=output_shape, dtype=np.float32)\n",
    "\n",
    "    # Constants\n",
    "    whitelist1_const = gs.Constant(\n",
    "        \"whitelist1\", values=np.array(whitelist1, dtype=np.int64)\n",
    "    )\n",
    "    whitelist2_const = gs.Constant(\n",
    "        \"whitelist2\", values=np.array(whitelist2, dtype=np.int64)\n",
    "    )\n",
    "    zero_const = gs.Constant(\"zero\", values=np.array(0.0, dtype=np.float32))\n",
    "    two_const = gs.Constant(\"two\", values=np.array(2.0, dtype=np.float32))\n",
    "    scale_const_node = gs.Constant(\n",
    "        \"scale\", values=np.array(scale_const, dtype=np.float32)\n",
    "    )\n",
    "    axes_unsq = gs.Constant(\"axes_unsq\", values=np.array([1], dtype=np.int64))\n",
    "    axes_reduce = gs.Constant(\"axes_reduce\", values=np.array([1], dtype=np.int64))\n",
    "\n",
    "    # Nodes for whitelist1 check\n",
    "    argmax1 = gs.Node(\n",
    "        op=\"ArgMax\", inputs=[logits1], outputs=[class1], attrs={\"axis\": 1, \"keepdims\": 0}\n",
    "    )\n",
    "    unsqueeze1 = gs.Node(\n",
    "        op=\"Unsqueeze\", inputs=[class1, axes_unsq], outputs=[class1_unsq]\n",
    "    )\n",
    "    equal1 = gs.Node(op=\"Equal\", inputs=[class1_unsq, whitelist1_const], outputs=[eq1])\n",
    "    cast1_node = gs.Node(\n",
    "        op=\"Cast\", inputs=[eq1], outputs=[cast1], attrs={\"to\": onnx.TensorProto.FLOAT}\n",
    "    )\n",
    "    reducesum1 = gs.Node(\n",
    "        op=\"ReduceSum\",\n",
    "        inputs=[cast1, axes_reduce],\n",
    "        outputs=[reduce1],\n",
    "        attrs={\"keepdims\": 1},\n",
    "    )\n",
    "    greater1 = gs.Node(op=\"Greater\", inputs=[reduce1, zero_const], outputs=[is_in1])\n",
    "\n",
    "    # Nodes for whitelist2 check\n",
    "    argmax2 = gs.Node(\n",
    "        op=\"ArgMax\", inputs=[logits2], outputs=[class2], attrs={\"axis\": 1, \"keepdims\": 0}\n",
    "    )\n",
    "    unsqueeze2 = gs.Node(\n",
    "        op=\"Unsqueeze\", inputs=[class2, axes_unsq], outputs=[class2_unsq]\n",
    "    )\n",
    "    equal2 = gs.Node(op=\"Equal\", inputs=[class2_unsq, whitelist2_const], outputs=[eq2])\n",
    "    cast2_node = gs.Node(\n",
    "        op=\"Cast\", inputs=[eq2], outputs=[cast2], attrs={\"to\": onnx.TensorProto.FLOAT}\n",
    "    )\n",
    "    reducesum2 = gs.Node(\n",
    "        op=\"ReduceSum\",\n",
    "        inputs=[cast2, axes_reduce],\n",
    "        outputs=[reduce2],\n",
    "        attrs={\"keepdims\": 1},\n",
    "    )\n",
    "    greater2 = gs.Node(op=\"Greater\", inputs=[reduce2, zero_const], outputs=[is_in2])\n",
    "\n",
    "    # Dynamic shape for expand\n",
    "    shape_node = gs.Node(op=\"Shape\", inputs=[logits1], outputs=[logits_shape_var])\n",
    "\n",
    "    expand1 = gs.Node(\n",
    "        op=\"Expand\", inputs=[is_in1, logits_shape_var], outputs=[is_in1_exp]\n",
    "    )\n",
    "    expand2 = gs.Node(\n",
    "        op=\"Expand\", inputs=[is_in2, logits_shape_var], outputs=[is_in2_exp]\n",
    "    )\n",
    "\n",
    "    # Combine logic\n",
    "    add_logits = gs.Node(op=\"Add\", inputs=[logits1, logits2], outputs=[add_output])\n",
    "    avg_node = gs.Node(op=\"Div\", inputs=[add_output, two_const], outputs=[avg_logits])\n",
    "    inner_where = gs.Node(\n",
    "        op=\"Where\",\n",
    "        inputs=[is_in2_exp, logits2, avg_logits],\n",
    "        outputs=[inner_selected],\n",
    "    )\n",
    "    outer_where = gs.Node(\n",
    "        op=\"Where\",\n",
    "        inputs=[is_in1_exp, logits1, inner_selected],\n",
    "        outputs=[selected_logits],\n",
    "    )\n",
    "    scale_mul = gs.Node(\n",
    "        op=\"Mul\", inputs=[selected_logits, scale_const_node], outputs=[scaled_logits]\n",
    "    )\n",
    "    softmax_final = gs.Node(\n",
    "        op=\"Softmax\", inputs=[scaled_logits], outputs=[final_output], attrs={\"axis\": 1}\n",
    "    )\n",
    "\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: final_output\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes\n",
    "        + graph2.nodes\n",
    "        + [\n",
    "            argmax1,\n",
    "            unsqueeze1,\n",
    "            equal1,\n",
    "            cast1_node,\n",
    "            reducesum1,\n",
    "            greater1,\n",
    "            argmax2,\n",
    "            unsqueeze2,\n",
    "            equal2,\n",
    "            cast2_node,\n",
    "            reducesum2,\n",
    "            greater2,\n",
    "            shape_node,\n",
    "            expand1,\n",
    "            expand2,\n",
    "            add_logits,\n",
    "            avg_node,\n",
    "            inner_where,\n",
    "            outer_where,\n",
    "            scale_mul,\n",
    "            softmax_final,\n",
    "        ],\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[final_output],\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# Usage example (replace with your actual whitelists)\n",
    "whitelist1=[1, 2, 4, 8, 9]\n",
    "whitelist2=[0, 3, 10, 5, 6, 7]\n",
    "combined = create_combined_onnx(\n",
    "    \"../../models/2025-11-27/speechmaster/62_model94.onnx\",\n",
    "    \"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "    whitelist1,\n",
    "    whitelist2,\n",
    "    3.0,\n",
    "    \"../../models/combine/2025-11-27/62vs18.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc499e9",
   "metadata": {},
   "source": [
    "#### Strategy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adfdda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined model saved: ../../models/combine/2025-11-27/62vs18_exclusive.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def _fix_reduction_nodes(graph: gs.Graph) -> None:\n",
    "    for node in graph.nodes:\n",
    "        if node.op in {\"ReduceMean\", \"ReduceL2\"} and len(node.inputs) == 2:\n",
    "            data, axes = node.inputs\n",
    "            const = next(\n",
    "                (n for n in graph.nodes if n.op == \"Constant\" and n.outputs[0] is axes),\n",
    "                None,\n",
    "            )\n",
    "            if const and hasattr(const.attrs[\"value\"], \"values\"):\n",
    "                node.inputs = [data]\n",
    "                node.attrs[\"axes\"] = const.attrs[\"value\"].values.tolist()\n",
    "                node.attrs[\"keepdims\"] = 1\n",
    "\n",
    "\n",
    "def _share_inputs_and_rename(g1: gs.Graph, g2: gs.Graph, prefix: str = \"m2_\"):\n",
    "    img = g1.inputs[0]\n",
    "    demo = g1.inputs[1]\n",
    "    img.name = \"image\"\n",
    "    demo.name = \"demographics\"\n",
    "\n",
    "    old_img, old_demo = g2.inputs[0], g2.inputs[1]\n",
    "    skip = {id(old_img), id(old_demo)}\n",
    "    for v in g2.tensors().values():\n",
    "        if id(v) not in skip and v.name:\n",
    "            v.name = prefix + v.name\n",
    "    for n in g2.nodes:\n",
    "        if n.name:\n",
    "            n.name = prefix + n.name\n",
    "\n",
    "    for n in g2.nodes:\n",
    "        for i, inp in enumerate(n.inputs):\n",
    "            if inp is old_img:\n",
    "                n.inputs[i] = img\n",
    "            if inp is old_demo:\n",
    "                n.inputs[i] = demo\n",
    "    g2.inputs = [img, demo]\n",
    "    return img, demo\n",
    "\n",
    "\n",
    "def create_combined_onnx(\n",
    "    model_path1: str,\n",
    "    model_path2: str,\n",
    "    whitelist1: List[int],\n",
    "    whitelist2: List[int],\n",
    "    scale_factor: float = 3.0,\n",
    "    output_path: str = \"combined.onnx\",\n",
    ") -> onnx.ModelProto:\n",
    "    # Load & prepare graphs\n",
    "    g1 = gs.import_onnx(onnx.load(model_path1))\n",
    "    g2 = gs.import_onnx(onnx.load(model_path2))\n",
    "    _fix_reduction_nodes(g1)\n",
    "    _fix_reduction_nodes(g2)\n",
    "    img_input, demo_input = _share_inputs_and_rename(g1, g2, \"m2_\")\n",
    "\n",
    "    logits1 = g1.outputs[0]\n",
    "    logits2 = g2.outputs[0]\n",
    "    logits1.name = \"logits_m1\"\n",
    "    logits2.name = \"logits_m2\"\n",
    "\n",
    "    num_classes = logits1.shape[1] if logits1.shape and len(logits1.shape) == 2 else 11\n",
    "    batch_shape = (None, num_classes)\n",
    "\n",
    "    # Constants\n",
    "    w1 = gs.Constant(\"w1\", np.array(whitelist1, np.int64))\n",
    "    w2 = gs.Constant(\"w2\", np.array(whitelist2, np.int64))\n",
    "    zero = gs.Constant(\"zero\", np.array(0.0, np.float32))\n",
    "    two = gs.Constant(\"two\", np.array(2.0, np.float32))\n",
    "    scale = gs.Constant(\"scale\", np.array(scale_factor, np.float32))\n",
    "    axis1 = gs.Constant(\"axis1\", np.array([1], np.int64))\n",
    "\n",
    "    # Helper: membership test that works with ReduceSum\n",
    "    def membership_nodes(\n",
    "        class_unsq: gs.Variable, whitelist_const: gs.Constant, prefix: str\n",
    "    ):\n",
    "        eq = gs.Variable(f\"{prefix}_eq\", dtype=np.bool)\n",
    "        cast = gs.Variable(f\"{prefix}_cast\", dtype=np.float32)\n",
    "        reduced = gs.Variable(f\"{prefix}_reduced\", dtype=np.float32, shape=[\"batch\", 1])\n",
    "        is_member = gs.Variable(f\"{prefix}_member\", dtype=np.bool, shape=[\"batch\", 1])\n",
    "\n",
    "        nodes = [\n",
    "            gs.Node(\n",
    "                op=\"Equal\",\n",
    "                name=f\"eq_{prefix}\",\n",
    "                inputs=[class_unsq, whitelist_const],\n",
    "                outputs=[eq],\n",
    "            ),\n",
    "            gs.Node(\n",
    "                op=\"Cast\",\n",
    "                name=f\"cast_{prefix}\",\n",
    "                inputs=[eq],\n",
    "                outputs=[cast],\n",
    "                attrs={\"to\": onnx.TensorProto.FLOAT},\n",
    "            ),\n",
    "            gs.Node(\n",
    "                op=\"ReduceSum\",\n",
    "                name=f\"red_{prefix}\",\n",
    "                inputs=[cast, axis1],\n",
    "                outputs=[reduced],\n",
    "                attrs={\"keepdims\": 1},\n",
    "            ),\n",
    "            gs.Node(\n",
    "                op=\"Greater\",\n",
    "                name=f\"gt_{prefix}\",\n",
    "                inputs=[reduced, zero],\n",
    "                outputs=[is_member],\n",
    "            ),\n",
    "        ]\n",
    "        return nodes, is_member\n",
    "\n",
    "    # ArgMax + Unsqueeze\n",
    "    c1 = gs.Variable(\"c1\", np.int64, [\"batch\"])\n",
    "    c2 = gs.Variable(\"c2\", np.int64, [\"batch\"])\n",
    "    c1_u = gs.Variable(\"c1_u\", np.int64, [\"batch\", 1])\n",
    "    c2_u = gs.Variable(\"c2_u\", np.int64, [\"batch\", 1])\n",
    "\n",
    "    nodes = [\n",
    "        gs.Node(\n",
    "            op=\"ArgMax\",\n",
    "            name=\"argmax1\",\n",
    "            inputs=[logits1],\n",
    "            outputs=[c1],\n",
    "            attrs={\"axis\": 1, \"keepdims\": 0},\n",
    "        ),\n",
    "        gs.Node(\n",
    "            op=\"ArgMax\",\n",
    "            name=\"argmax2\",\n",
    "            inputs=[logits2],\n",
    "            outputs=[c2],\n",
    "            attrs={\"axis\": 1, \"keepdims\": 0},\n",
    "        ),\n",
    "        gs.Node(op=\"Unsqueeze\", name=\"unsq1\", inputs=[c1, axis1], outputs=[c1_u]),\n",
    "        gs.Node(op=\"Unsqueeze\", name=\"unsq2\", inputs=[c2, axis1], outputs=[c2_u]),\n",
    "    ]\n",
    "\n",
    "    # Membership checks\n",
    "    n1, m1_in_w1 = membership_nodes(c1_u, w1, \"m1_w1\")\n",
    "    n2, m1_in_w2 = membership_nodes(c1_u, w2, \"m1_w2\")\n",
    "    n3, m2_in_w1 = membership_nodes(c2_u, w1, \"m2_w1\")\n",
    "    n4, m2_in_w2 = membership_nodes(c2_u, w2, \"m2_w2\")\n",
    "    nodes += n1 + n2 + n3 + n4\n",
    "\n",
    "    # Conditions\n",
    "    m1_not_w2 = gs.Variable(\"m1_not_w2\", np.bool, [\"batch\", 1])\n",
    "    m2_not_w1 = gs.Variable(\"m2_not_w1\", np.bool, [\"batch\", 1])\n",
    "    use_m1 = gs.Variable(\"use_model1\", np.bool, [\"batch\", 1])\n",
    "    use_m2 = gs.Variable(\"use_model2\", np.bool, [\"batch\", 1])\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Not\", name=\"not1\", inputs=[m1_in_w2], outputs=[m1_not_w2]),\n",
    "        gs.Node(op=\"Not\", name=\"not2\", inputs=[m2_in_w1], outputs=[m2_not_w1]),\n",
    "        gs.Node(\n",
    "            op=\"And\", name=\"and_m1\", inputs=[m1_in_w1, m1_not_w2], outputs=[use_m1]\n",
    "        ),\n",
    "        gs.Node(\n",
    "            op=\"And\", name=\"and_m2\", inputs=[m2_not_w1, m2_in_w2], outputs=[use_m2]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Expand masks\n",
    "    shape_var = gs.Variable(\"shape\", np.int64, [2])\n",
    "    use_m1_exp = gs.Variable(\"use_m1_exp\", np.bool, batch_shape)\n",
    "    use_m2_exp = gs.Variable(\"use_m2_exp\", np.bool, batch_shape)\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Shape\", name=\"shape\", inputs=[logits1], outputs=[shape_var]),\n",
    "        gs.Node(\n",
    "            op=\"Expand\", name=\"exp_m1\", inputs=[use_m1, shape_var], outputs=[use_m1_exp]\n",
    "        ),\n",
    "        gs.Node(\n",
    "            op=\"Expand\", name=\"exp_m2\", inputs=[use_m2, shape_var], outputs=[use_m2_exp]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Average fallback\n",
    "    sum_ab = gs.Variable(\"sum\", np.float32, batch_shape)\n",
    "    avg = gs.Variable(\"avg\", np.float32, batch_shape)\n",
    "    temp = gs.Variable(\"temp\", np.float32, batch_shape)\n",
    "    selected = gs.Variable(\"selected\", np.float32, batch_shape)\n",
    "    scaled = gs.Variable(\"scaled\", np.float32, batch_shape)\n",
    "    probs = gs.Variable(\"probabilities\", np.float32, batch_shape)\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Add\", name=\"add\", inputs=[logits1, logits2], outputs=[sum_ab]),\n",
    "        gs.Node(op=\"Div\", name=\"div\", inputs=[sum_ab, two], outputs=[avg]),\n",
    "        gs.Node(\n",
    "            op=\"Where\",\n",
    "            name=\"where_m2\",\n",
    "            inputs=[use_m2_exp, logits2, avg],\n",
    "            outputs=[temp],\n",
    "        ),\n",
    "        gs.Node(\n",
    "            op=\"Where\",\n",
    "            name=\"where_final\",\n",
    "            inputs=[use_m1_exp, logits1, temp],\n",
    "            outputs=[selected],\n",
    "        ),\n",
    "        gs.Node(op=\"Mul\", name=\"mul\", inputs=[selected, scale], outputs=[scaled]),\n",
    "        gs.Node(\n",
    "            op=\"Softmax\",\n",
    "            name=\"softmax\",\n",
    "            inputs=[scaled],\n",
    "            outputs=[probs],\n",
    "            attrs={\"axis\": 1},\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Final graph\n",
    "    graph = gs.Graph(\n",
    "        nodes=g1.nodes + g2.nodes + nodes,\n",
    "        inputs=[img_input, demo_input],\n",
    "        outputs=[probs],\n",
    "        opset=17,\n",
    "    )\n",
    "\n",
    "    model = gs.export_onnx(graph.cleanup().toposort())\n",
    "    model = shape_inference.infer_shapes(model)\n",
    "    onnx.checker.check_model(model, full_check=True)  # now passes!\n",
    "    onnx.save(model, output_path)\n",
    "    print(f\"Combined model saved: {output_path}\")\n",
    "    # return model\n",
    "\n",
    "\n",
    "# === RUN ===\n",
    "create_combined_onnx(\n",
    "    model_path1=\"../../models/2025-11-27/speechmaster/62_model94.onnx\",\n",
    "    model_path2=\"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "    whitelist1=[1, 2, 4, 8, 9],\n",
    "    whitelist2=[0, 3, 10, 5, 6, 7],\n",
    "    scale_factor=3.0,\n",
    "    output_path=\"../../models/combine/2025-11-27/62vs18_exclusive.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa897c",
   "metadata": {},
   "source": [
    "### Combining 18 vs 122"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479ee9e",
   "metadata": {},
   "source": [
    "#### Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a50bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model1] Total ReduceMean nodes: 34, Fixed: 0\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.1/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.1/blocks.1.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  ... and 31 more\n",
      "[Model2] Total ReduceMean nodes: 34, Fixed: 0\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.1/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.1/blocks.1.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  ... and 31 more\n",
      "No reduction fixes applied - check debug output above\n",
      "Inferred output shape: [None, 11]\n",
      "Combined ONNX model saved to ../../models/combine/2025-11-27/18vs122.onnx\n",
      "Output shape: [None, 11]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in [\"ReduceL2\", \"ReduceMean\"]:\n",
    "            debug_nodes.append(\n",
    "                {\n",
    "                    \"name\": node.name,\n",
    "                    \"op\": node.op,\n",
    "                    \"inputs_count\": len(node.inputs),\n",
    "                    \"inputs_types\": [type(inp).__name__ for inp in node.inputs],\n",
    "                    \"second_input_name\": (\n",
    "                        node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (\n",
    "                        c_node.op == \"Constant\"\n",
    "                        and c_node.outputs\n",
    "                        and len(c_node.outputs) == 1\n",
    "                        and c_node.outputs[0].name == axes_var.name\n",
    "                    ):\n",
    "                        constant_node = c_node\n",
    "                        if \"value\" in c_node.attrs:\n",
    "                            axes_values = c_node.attrs[\"value\"].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs[\"axes\"] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if \"keepdims\" not in node.attrs:\n",
    "                        node.attrs[\"keepdims\"] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\"\n",
    "                    )\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\"\n",
    "                    )\n",
    "    if debug_nodes:\n",
    "        print(\n",
    "            f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\"\n",
    "        )\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(\n",
    "                f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\"\n",
    "            )\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(\n",
    "    graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None\n",
    "):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename the shared input Variable object.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    tensors = list(graph.tensors().values())\n",
    "    for var in tensors:\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(\n",
    "    model_path1,\n",
    "    model_path2,\n",
    "    whitelist1: List[int],\n",
    "    whitelist2: List[int],\n",
    "    scale_const: float = 3.0,\n",
    "    output_path=\"combined.onnx\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one with conditional logic based on whitelists for skin cancer strategy:\n",
    "    - Compute logits1 from model1.\n",
    "    - If argmax(logits1) in whitelist1, use logits1.\n",
    "    - Else compute logits2 from model2.\n",
    "    - If argmax(logits2) in whitelist2, use logits2.\n",
    "    - Else use average of logits1 and logits2.\n",
    "    - Then scale the chosen logits by scale_const and apply softmax for output.\n",
    "\n",
    "    Assumes:\n",
    "    - Both models take 'image' and 'demographics' as inputs.\n",
    "    - Both output a single tensor of shape [batch_size, num_classes] (logits).\n",
    "    - Whitelists are lists of class indices (integers).\n",
    "    - You need to pip install onnx onnx-graphsurgeon if not already installed.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Assume input names and order based on your code\n",
    "    # Rename for clarity\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = \"image\"\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = \"demographics\"\n",
    "\n",
    "    # Share the inputs with model2\n",
    "    old_image_input = graph2.inputs[0]\n",
    "    old_demo_input = graph2.inputs[1]\n",
    "\n",
    "    _rename_graph_tensors_and_nodes(\n",
    "        graph2, prefix=\"g2_\", skip_vars=[old_image_input, old_demo_input]\n",
    "    )\n",
    "\n",
    "    # Replace all references in graph2 nodes to use shared inputs\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = image_input\n",
    "            if node.inputs[i] is old_demo_input:\n",
    "                node.inputs[i] = demographics_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared inputs\n",
    "    graph2.inputs[0] = image_input\n",
    "    graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = \"logits1\"\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = \"logits2\"\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 11  # Fallback assumption\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 11]  # Fallback\n",
    "        num_classes = 11\n",
    "        print(\n",
    "            f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 11]\"\n",
    "        )\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define variables\n",
    "    class1 = gs.Variable(\"class1\", shape=[None], dtype=np.int64)\n",
    "    class1_unsq = gs.Variable(\"class1_unsq\", shape=[None, 1], dtype=np.int64)\n",
    "    eq1 = gs.Variable(\"eq1\", shape=[None, len(whitelist1)], dtype=np.bool)\n",
    "    cast1 = gs.Variable(\"cast1\", shape=[None, len(whitelist1)], dtype=np.float32)\n",
    "    reduce1 = gs.Variable(\"reduce1\", shape=[None, 1], dtype=np.float32)\n",
    "    is_in1 = gs.Variable(\"is_in1\", shape=[None, 1], dtype=np.bool)\n",
    "    is_in1_exp = gs.Variable(\"is_in1_exp\", shape=output_shape, dtype=np.bool)\n",
    "\n",
    "    class2 = gs.Variable(\"class2\", shape=[None], dtype=np.int64)\n",
    "    class2_unsq = gs.Variable(\"class2_unsq\", shape=[None, 1], dtype=np.int64)\n",
    "    eq2 = gs.Variable(\"eq2\", shape=[None, len(whitelist2)], dtype=np.bool)\n",
    "    cast2 = gs.Variable(\"cast2\", shape=[None, len(whitelist2)], dtype=np.float32)\n",
    "    reduce2 = gs.Variable(\"reduce2\", shape=[None, 1], dtype=np.float32)\n",
    "    is_in2 = gs.Variable(\"is_in2\", shape=[None, 1], dtype=np.bool)\n",
    "    is_in2_exp = gs.Variable(\"is_in2_exp\", shape=output_shape, dtype=np.bool)\n",
    "\n",
    "    logits_shape_var = gs.Variable(\"logits_shape\", dtype=np.int64, shape=[2])\n",
    "\n",
    "    add_output = gs.Variable(\"add_output\", shape=output_shape, dtype=np.float32)\n",
    "    avg_logits = gs.Variable(\"avg_logits\", shape=output_shape, dtype=np.float32)\n",
    "    inner_selected = gs.Variable(\"inner_selected\", shape=output_shape, dtype=np.float32)\n",
    "    selected_logits = gs.Variable(\n",
    "        \"selected_logits\", shape=output_shape, dtype=np.float32\n",
    "    )\n",
    "    scaled_logits = gs.Variable(\"scaled_logits\", shape=output_shape, dtype=np.float32)\n",
    "    final_output = gs.Variable(\"final_output\", shape=output_shape, dtype=np.float32)\n",
    "\n",
    "    # Constants\n",
    "    whitelist1_const = gs.Constant(\n",
    "        \"whitelist1\", values=np.array(whitelist1, dtype=np.int64)\n",
    "    )\n",
    "    whitelist2_const = gs.Constant(\n",
    "        \"whitelist2\", values=np.array(whitelist2, dtype=np.int64)\n",
    "    )\n",
    "    zero_const = gs.Constant(\"zero\", values=np.array(0.0, dtype=np.float32))\n",
    "    two_const = gs.Constant(\"two\", values=np.array(2.0, dtype=np.float32))\n",
    "    scale_const_node = gs.Constant(\n",
    "        \"scale\", values=np.array(scale_const, dtype=np.float32)\n",
    "    )\n",
    "    axes_unsq = gs.Constant(\"axes_unsq\", values=np.array([1], dtype=np.int64))\n",
    "    axes_reduce = gs.Constant(\"axes_reduce\", values=np.array([1], dtype=np.int64))\n",
    "\n",
    "    # Nodes for whitelist1 check\n",
    "    argmax1 = gs.Node(\n",
    "        op=\"ArgMax\", inputs=[logits1], outputs=[class1], attrs={\"axis\": 1, \"keepdims\": 0}\n",
    "    )\n",
    "    unsqueeze1 = gs.Node(\n",
    "        op=\"Unsqueeze\", inputs=[class1, axes_unsq], outputs=[class1_unsq]\n",
    "    )\n",
    "    equal1 = gs.Node(op=\"Equal\", inputs=[class1_unsq, whitelist1_const], outputs=[eq1])\n",
    "    cast1_node = gs.Node(\n",
    "        op=\"Cast\", inputs=[eq1], outputs=[cast1], attrs={\"to\": onnx.TensorProto.FLOAT}\n",
    "    )\n",
    "    reducesum1 = gs.Node(\n",
    "        op=\"ReduceSum\",\n",
    "        inputs=[cast1, axes_reduce],\n",
    "        outputs=[reduce1],\n",
    "        attrs={\"keepdims\": 1},\n",
    "    )\n",
    "    greater1 = gs.Node(op=\"Greater\", inputs=[reduce1, zero_const], outputs=[is_in1])\n",
    "\n",
    "    # Nodes for whitelist2 check\n",
    "    argmax2 = gs.Node(\n",
    "        op=\"ArgMax\", inputs=[logits2], outputs=[class2], attrs={\"axis\": 1, \"keepdims\": 0}\n",
    "    )\n",
    "    unsqueeze2 = gs.Node(\n",
    "        op=\"Unsqueeze\", inputs=[class2, axes_unsq], outputs=[class2_unsq]\n",
    "    )\n",
    "    equal2 = gs.Node(op=\"Equal\", inputs=[class2_unsq, whitelist2_const], outputs=[eq2])\n",
    "    cast2_node = gs.Node(\n",
    "        op=\"Cast\", inputs=[eq2], outputs=[cast2], attrs={\"to\": onnx.TensorProto.FLOAT}\n",
    "    )\n",
    "    reducesum2 = gs.Node(\n",
    "        op=\"ReduceSum\",\n",
    "        inputs=[cast2, axes_reduce],\n",
    "        outputs=[reduce2],\n",
    "        attrs={\"keepdims\": 1},\n",
    "    )\n",
    "    greater2 = gs.Node(op=\"Greater\", inputs=[reduce2, zero_const], outputs=[is_in2])\n",
    "\n",
    "    # Dynamic shape for expand\n",
    "    shape_node = gs.Node(op=\"Shape\", inputs=[logits1], outputs=[logits_shape_var])\n",
    "\n",
    "    expand1 = gs.Node(\n",
    "        op=\"Expand\", inputs=[is_in1, logits_shape_var], outputs=[is_in1_exp]\n",
    "    )\n",
    "    expand2 = gs.Node(\n",
    "        op=\"Expand\", inputs=[is_in2, logits_shape_var], outputs=[is_in2_exp]\n",
    "    )\n",
    "\n",
    "    # Combine logic\n",
    "    add_logits = gs.Node(op=\"Add\", inputs=[logits1, logits2], outputs=[add_output])\n",
    "    avg_node = gs.Node(op=\"Div\", inputs=[add_output, two_const], outputs=[avg_logits])\n",
    "    inner_where = gs.Node(\n",
    "        op=\"Where\",\n",
    "        inputs=[is_in2_exp, logits2, avg_logits],\n",
    "        outputs=[inner_selected],\n",
    "    )\n",
    "    outer_where = gs.Node(\n",
    "        op=\"Where\",\n",
    "        inputs=[is_in1_exp, logits1, inner_selected],\n",
    "        outputs=[selected_logits],\n",
    "    )\n",
    "    scale_mul = gs.Node(\n",
    "        op=\"Mul\", inputs=[selected_logits, scale_const_node], outputs=[scaled_logits]\n",
    "    )\n",
    "    softmax_final = gs.Node(\n",
    "        op=\"Softmax\", inputs=[scaled_logits], outputs=[final_output], attrs={\"axis\": 1}\n",
    "    )\n",
    "\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: final_output\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes\n",
    "        + graph2.nodes\n",
    "        + [\n",
    "            argmax1,\n",
    "            unsqueeze1,\n",
    "            equal1,\n",
    "            cast1_node,\n",
    "            reducesum1,\n",
    "            greater1,\n",
    "            argmax2,\n",
    "            unsqueeze2,\n",
    "            equal2,\n",
    "            cast2_node,\n",
    "            reducesum2,\n",
    "            greater2,\n",
    "            shape_node,\n",
    "            expand1,\n",
    "            expand2,\n",
    "            add_logits,\n",
    "            avg_node,\n",
    "            inner_where,\n",
    "            outer_where,\n",
    "            scale_mul,\n",
    "            softmax_final,\n",
    "        ],\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[final_output],\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# Usage example (replace with your actual whitelists)\n",
    "whitelist18=[0, 3, 4, 10]\n",
    "whitelist122=[1, 2, 5, 8, 9]  # Example: classes for model2\n",
    "# whitelist1=[0, 3, 10, 9, 6, 7]\n",
    "# whitelist2=[1, 2, 4, 5, 8]  # Example: classes for model2\n",
    "combined = create_combined_onnx(\n",
    "    \"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "    \"../../models/2025-11-27/speechmaster/122_model123.onnx\",\n",
    "    whitelist1=whitelist18,\n",
    "    whitelist2=whitelist122,\n",
    "    scale_const=3.0,\n",
    "    output_path=\"../../models/combine/2025-11-27/18vs122.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e0c14",
   "metadata": {},
   "source": [
    "#### Strategy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "498fcffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined model saved: ../../models/combine/2025-11-27/122vs18_exclusive.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def _fix_reduction_nodes(graph: gs.Graph) -> None:\n",
    "    for node in graph.nodes:\n",
    "        if node.op in {\"ReduceMean\", \"ReduceL2\"} and len(node.inputs) == 2:\n",
    "            data, axes = node.inputs\n",
    "            const = next((n for n in graph.nodes if n.op == \"Constant\" and n.outputs[0] is axes), None)\n",
    "            if const and hasattr(const.attrs[\"value\"], \"values\"):\n",
    "                node.inputs = [data]\n",
    "                node.attrs[\"axes\"] = const.attrs[\"value\"].values.tolist()\n",
    "                node.attrs[\"keepdims\"] = 1\n",
    "\n",
    "\n",
    "def _share_inputs_and_rename(g1: gs.Graph, g2: gs.Graph, prefix: str = \"m2_\"):\n",
    "    img = g1.inputs[0]\n",
    "    demo = g1.inputs[1]\n",
    "    img.name = \"image\"\n",
    "    demo.name = \"demographics\"\n",
    "\n",
    "    old_img, old_demo = g2.inputs[0], g2.inputs[1]\n",
    "    skip = {id(old_img), id(old_demo)}\n",
    "    for v in g2.tensors().values():\n",
    "        if id(v) not in skip and v.name:\n",
    "            v.name = prefix + v.name\n",
    "    for n in g2.nodes:\n",
    "        if n.name:\n",
    "            n.name = prefix + n.name\n",
    "\n",
    "    for n in g2.nodes:\n",
    "        for i, inp in enumerate(n.inputs):\n",
    "            if inp is old_img:\n",
    "                n.inputs[i] = img\n",
    "            if inp is old_demo:\n",
    "                n.inputs[i] = demo\n",
    "    g2.inputs = [img, demo]\n",
    "    return img, demo\n",
    "\n",
    "\n",
    "def create_combined_onnx(\n",
    "    model_path1: str,\n",
    "    model_path2: str,\n",
    "    whitelist1: List[int],\n",
    "    whitelist2: List[int],\n",
    "    scale_factor: float = 3.0,\n",
    "    output_path: str = \"combined.onnx\",\n",
    ") -> onnx.ModelProto:\n",
    "    # Load & prepare graphs\n",
    "    g1 = gs.import_onnx(onnx.load(model_path1))\n",
    "    g2 = gs.import_onnx(onnx.load(model_path2))\n",
    "    _fix_reduction_nodes(g1)\n",
    "    _fix_reduction_nodes(g2)\n",
    "    img_input, demo_input = _share_inputs_and_rename(g1, g2, \"m2_\")\n",
    "\n",
    "    logits1 = g1.outputs[0]\n",
    "    logits2 = g2.outputs[0]\n",
    "    logits1.name = \"logits_m1\"\n",
    "    logits2.name = \"logits_m2\"\n",
    "\n",
    "    num_classes = logits1.shape[1] if logits1.shape and len(logits1.shape) == 2 else 11\n",
    "    batch_shape = (None, num_classes)\n",
    "\n",
    "    # Constants\n",
    "    w1 = gs.Constant(\"w1\", np.array(whitelist1, np.int64))\n",
    "    w2 = gs.Constant(\"w2\", np.array(whitelist2, np.int64))\n",
    "    zero = gs.Constant(\"zero\", np.array(0.0, np.float32))\n",
    "    two = gs.Constant(\"two\", np.array(2.0, np.float32))\n",
    "    scale = gs.Constant(\"scale\", np.array(scale_factor, np.float32))\n",
    "    axis1 = gs.Constant(\"axis1\", np.array([1], np.int64))\n",
    "\n",
    "    # Helper: membership test that works with ReduceSum\n",
    "    def membership_nodes(class_unsq: gs.Variable, whitelist_const: gs.Constant, prefix: str):\n",
    "        eq = gs.Variable(f\"{prefix}_eq\", dtype=np.bool)\n",
    "        cast = gs.Variable(f\"{prefix}_cast\", dtype=np.float32)\n",
    "        reduced = gs.Variable(f\"{prefix}_reduced\", dtype=np.float32, shape=[\"batch\", 1])\n",
    "        is_member = gs.Variable(f\"{prefix}_member\", dtype=np.bool, shape=[\"batch\", 1])\n",
    "\n",
    "        nodes = [\n",
    "            gs.Node(op=\"Equal\", name=f\"eq_{prefix}\", inputs=[class_unsq, whitelist_const], outputs=[eq]),\n",
    "            gs.Node(op=\"Cast\", name=f\"cast_{prefix}\", inputs=[eq], outputs=[cast],\n",
    "                    attrs={\"to\": onnx.TensorProto.FLOAT}),\n",
    "            gs.Node(op=\"ReduceSum\", name=f\"red_{prefix}\", inputs=[cast, axis1],\n",
    "                    outputs=[reduced], attrs={\"keepdims\": 1}),\n",
    "            gs.Node(op=\"Greater\", name=f\"gt_{prefix}\", inputs=[reduced, zero], outputs=[is_member]),\n",
    "        ]\n",
    "        return nodes, is_member\n",
    "\n",
    "    # ArgMax + Unsqueeze\n",
    "    c1 = gs.Variable(\"c1\", np.int64, [\"batch\"])\n",
    "    c2 = gs.Variable(\"c2\", np.int64, [\"batch\"])\n",
    "    c1_u = gs.Variable(\"c1_u\", np.int64, [\"batch\", 1])\n",
    "    c2_u = gs.Variable(\"c2_u\", np.int64, [\"batch\", 1])\n",
    "\n",
    "    nodes = [\n",
    "        gs.Node(op=\"ArgMax\", name=\"argmax1\", inputs=[logits1], outputs=[c1], attrs={\"axis\": 1, \"keepdims\": 0}),\n",
    "        gs.Node(op=\"ArgMax\", name=\"argmax2\", inputs=[logits2], outputs=[c2], attrs={\"axis\": 1, \"keepdims\": 0}),\n",
    "        gs.Node(op=\"Unsqueeze\", name=\"unsq1\", inputs=[c1, axis1], outputs=[c1_u]),\n",
    "        gs.Node(op=\"Unsqueeze\", name=\"unsq2\", inputs=[c2, axis1], outputs=[c2_u]),\n",
    "    ]\n",
    "\n",
    "    # Membership checks\n",
    "    n1, m1_in_w1 = membership_nodes(c1_u, w1, \"m1_w1\")\n",
    "    n2, m1_in_w2 = membership_nodes(c1_u, w2, \"m1_w2\")\n",
    "    n3, m2_in_w1 = membership_nodes(c2_u, w1, \"m2_w1\")\n",
    "    n4, m2_in_w2 = membership_nodes(c2_u, w2, \"m2_w2\")\n",
    "    nodes += n1 + n2 + n3 + n4\n",
    "\n",
    "    # Conditions\n",
    "    m1_not_w2 = gs.Variable(\"m1_not_w2\", np.bool, [\"batch\", 1])\n",
    "    m2_not_w1 = gs.Variable(\"m2_not_w1\", np.bool, [\"batch\", 1])\n",
    "    use_m1 = gs.Variable(\"use_model1\", np.bool, [\"batch\", 1])\n",
    "    use_m2 = gs.Variable(\"use_model2\", np.bool, [\"batch\", 1])\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Not\", name=\"not1\", inputs=[m1_in_w2], outputs=[m1_not_w2]),\n",
    "        gs.Node(op=\"Not\", name=\"not2\", inputs=[m2_in_w1], outputs=[m2_not_w1]),\n",
    "        gs.Node(op=\"And\", name=\"and_m1\", inputs=[m1_in_w1, m1_not_w2], outputs=[use_m1]),\n",
    "        gs.Node(op=\"And\", name=\"and_m2\", inputs=[m2_not_w1, m2_in_w2], outputs=[use_m2]),\n",
    "    ]\n",
    "\n",
    "    # Expand masks\n",
    "    shape_var = gs.Variable(\"shape\", np.int64, [2])\n",
    "    use_m1_exp = gs.Variable(\"use_m1_exp\", np.bool, batch_shape)\n",
    "    use_m2_exp = gs.Variable(\"use_m2_exp\", np.bool, batch_shape)\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Shape\", name=\"shape\", inputs=[logits1], outputs=[shape_var]),\n",
    "        gs.Node(op=\"Expand\", name=\"exp_m1\", inputs=[use_m1, shape_var], outputs=[use_m1_exp]),\n",
    "        gs.Node(op=\"Expand\", name=\"exp_m2\", inputs=[use_m2, shape_var], outputs=[use_m2_exp]),\n",
    "    ]\n",
    "\n",
    "    # Average fallback\n",
    "    sum_ab = gs.Variable(\"sum\", np.float32, batch_shape)\n",
    "    avg = gs.Variable(\"avg\", np.float32, batch_shape)\n",
    "    temp = gs.Variable(\"temp\", np.float32, batch_shape)\n",
    "    selected = gs.Variable(\"selected\", np.float32, batch_shape)\n",
    "    scaled = gs.Variable(\"scaled\", np.float32, batch_shape)\n",
    "    probs = gs.Variable(\"probabilities\", np.float32, batch_shape)\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Add\", name=\"add\", inputs=[logits1, logits2], outputs=[sum_ab]),\n",
    "        gs.Node(op=\"Div\", name=\"div\", inputs=[sum_ab, two], outputs=[avg]),\n",
    "        gs.Node(op=\"Where\", name=\"where_m2\", inputs=[use_m2_exp, logits2, avg], outputs=[temp]),\n",
    "        gs.Node(op=\"Where\", name=\"where_final\", inputs=[use_m1_exp, logits1, temp], outputs=[selected]),\n",
    "        gs.Node(op=\"Mul\", name=\"mul\", inputs=[selected, scale], outputs=[scaled]),\n",
    "        gs.Node(op=\"Softmax\", name=\"softmax\", inputs=[scaled], outputs=[probs], attrs={\"axis\": 1}),\n",
    "    ]\n",
    "\n",
    "    # Final graph\n",
    "    graph = gs.Graph(nodes=g1.nodes + g2.nodes + nodes,\n",
    "                     inputs=[img_input, demo_input],\n",
    "                     outputs=[probs],\n",
    "                     opset=17)\n",
    "\n",
    "    model = gs.export_onnx(graph.cleanup().toposort())\n",
    "    model = shape_inference.infer_shapes(model)\n",
    "    onnx.checker.check_model(model, full_check=True)   # now passes!\n",
    "    onnx.save(model, output_path)\n",
    "    print(f\"Combined model saved: {output_path}\")\n",
    "    # return model\n",
    "\n",
    "\n",
    "# Usage example (replace with your actual whitelists)\n",
    "whitelist18=[0, 3, 4, 10]\n",
    "whitelist122=[1, 2, 5, 8, 9]  \n",
    "combined = create_combined_onnx(\n",
    "    \"../../models/2025-11-27/speechmaster/122_model123.onnx\",\n",
    "    \"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "    whitelist1=whitelist122,\n",
    "    whitelist2=whitelist18,\n",
    "    scale_factor=3.0,\n",
    "    output_path=\"../../models/combine/2025-11-27/122vs18_exclusive.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875059be",
   "metadata": {},
   "source": [
    "### Combining 148 vs 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in ['ReduceL2', 'ReduceMean']:\n",
    "            debug_nodes.append({\n",
    "                'name': node.name,\n",
    "                'op': node.op,\n",
    "                'inputs_count': len(node.inputs),\n",
    "                'inputs_types': [type(inp).__name__ for inp in node.inputs],\n",
    "                'second_input_name': node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "            })\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (c_node.op == 'Constant' and \n",
    "                        c_node.outputs and len(c_node.outputs) == 1 and \n",
    "                        c_node.outputs[0].name == axes_var.name):\n",
    "                        constant_node = c_node\n",
    "                        if 'value' in c_node.attrs:\n",
    "                            axes_values = c_node.attrs['value'].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs['axes'] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if 'keepdims' not in node.attrs:\n",
    "                        node.attrs['keepdims'] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\")\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\")\n",
    "    if debug_nodes:\n",
    "        print(f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\")\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\")\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename the shared input Variable object.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    tensors = list(graph.tensors().values())\n",
    "    for var in tensors:\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(model_path1, model_path2, output_path='combined.onnx'):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one:\n",
    "    - Model1: takes 'image' and 'demographics' -> logits1\n",
    "    - Model2: takes 'image' -> logits2\n",
    "    - Combined: takes 'image' and 'demographics' -> (softmax(logits1) + logits2) / 2\n",
    "\n",
    "    Key changes vs. earlier: we rename the second graph's tensors/nodes with a prefix to avoid name collisions\n",
    "    and ensure the shared `image` input variable object is used by both graphs. This prevents duplicate tensor\n",
    "    names and topological ordering issues during checker validation.\n",
    "        \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Rename for clarity and sharing\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = 'image'\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = 'demographics'\n",
    "\n",
    "    # Grab model2's image input object BEFORE renaming so we can skip renaming that specific Variable\n",
    "    old_image_input = graph2.inputs[0]\n",
    "    old_demo_input = graph2.inputs[1]\n",
    "\n",
    "    # Rename graph2 tensors/nodes to avoid clashes (but don't rename the image Variable object)\n",
    "    _rename_graph_tensors_and_nodes(graph2, prefix='g2_', skip_vars=[old_image_input, old_demo_input])\n",
    "\n",
    "    # Replace all references in graph2 nodes from old_image_input to the shared image_input object\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = image_input\n",
    "            if node.inputs[i] is old_demo_input:\n",
    "                node.inputs[i] = demographics_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared input object (this removes a duplicate input with same name)\n",
    "    graph2.inputs[0] = image_input\n",
    "    graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = 'logits1'\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = 'logits2'\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 11  # Fallback assumption based on reported output size\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 11]  # Fallback\n",
    "        num_classes = 11\n",
    "        print(f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 10]\")\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define output variables WITH dtype and shape (no flattening)\n",
    "    probs1 = gs.Variable('probs1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    probs2 = gs.Variable('probs2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    sum_avg = gs.Variable('sum_avg', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output1 = gs.Variable('avg_output1', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    avg_output2 = gs.Variable('avg_output2', shape=output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "\n",
    "    # Softmax on first model (axis=1 for [batch, classes])\n",
    "    softmax1 = gs.Node(\n",
    "        op='Softmax',\n",
    "        inputs=[logits1],\n",
    "        outputs=[probs1],\n",
    "        attrs={'axis': 1}\n",
    "    )    \n",
    "    softmax2 = gs.Node(\n",
    "        op='Softmax',\n",
    "        inputs=[logits2],\n",
    "        outputs=[probs2],\n",
    "        attrs={'axis': 1}\n",
    "    )\n",
    "\n",
    "    # Average: (probs1 + logits2) / 2\n",
    "\n",
    "    constant_07 = gs.Constant(name='constant_07', values=np.array(0.3, dtype=np.float32))  # Scalar for broadcast\n",
    "    constant_03 = gs.Constant(name='constant_03', values=np.array(0.7, dtype=np.float32))  # Scalar for broadcast\n",
    "    mul1 = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[probs1, constant_03],\n",
    "        outputs=[avg_output1]\n",
    "    )\n",
    "    mul2 = gs.Node(\n",
    "        op='Mul',  # Equivalent to / 2\n",
    "        inputs=[probs2, constant_07],\n",
    "        outputs=[avg_output2]\n",
    "    )\n",
    "    add = gs.Node(\n",
    "        op='Add',\n",
    "        inputs=[avg_output1, avg_output2],\n",
    "        outputs=[sum_avg]\n",
    "    )\n",
    "\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: avg_output\n",
    "    # We put graph1 nodes first, then graph2 nodes (which we've namespaced) so producers appear before consumers.\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes + graph2.nodes + [softmax1, softmax2, mul1, mul2, add],\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[sum_avg]\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export - cleanup will remove unused nodes and should also fix ordering where possible\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "# Usage\n",
    "# Note: adjust paths as needed\n",
    "combined = create_combined_onnx('model/medicaldev_148.onnx', 'model/medicaldev_196.onnx', \"model/medicaldev_148_196.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2d0b7",
   "metadata": {},
   "source": [
    "### Combining 61 vs 62"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb57762",
   "metadata": {},
   "source": [
    "#### Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a065dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model1] Total ReduceMean nodes: 32, Fixed: 0\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.0/blocks.0.1/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /model/base_model/blocks/blocks.1/blocks.1.0/se/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  ... and 29 more\n",
      "[Model2] Total ReduceMean nodes: 34, Fixed: 0\n",
      "  - /cnn/features/features.1/features.1.0/block/block.1/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /cnn/features/features.1/features.1.1/block/block.1/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  - /cnn/features/features.2/features.2.0/block/block.2/ReduceMean: ReduceMean, 1 inputs, types: ['Variable'], second_name: None\n",
      "  ... and 31 more\n",
      "No reduction fixes applied - check debug output above\n",
      "Inferred output shape: [None, 11]\n",
      "Combined ONNX model saved to ../../models/combine/2025-11-27/62vs61.onnx\n",
      "Output shape: [None, 11]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fix_reduction_nodes(graph: gs.Graph, graph_name: str = \"unknown\"):\n",
    "    \"\"\"\n",
    "    Fixes ReduceL2 and ReduceMean nodes that incorrectly have axes as input (2 inputs) by moving axes to attribute.\n",
    "    Searches for the Constant node producing the axes Variable and extracts its value.\n",
    "    Removes the axes input and the unused Constant node after fix.\n",
    "    Adds debug prints for all ReduceL2 and ReduceMean nodes.\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "    removed_constants = 0\n",
    "    debug_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if node.op in [\"ReduceL2\", \"ReduceMean\"]:\n",
    "            debug_nodes.append(\n",
    "                {\n",
    "                    \"name\": node.name,\n",
    "                    \"op\": node.op,\n",
    "                    \"inputs_count\": len(node.inputs),\n",
    "                    \"inputs_types\": [type(inp).__name__ for inp in node.inputs],\n",
    "                    \"second_input_name\": (\n",
    "                        node.inputs[1].name if len(node.inputs) > 1 else None\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            if len(node.inputs) == 2:\n",
    "                data_input = node.inputs[0]\n",
    "                axes_var = node.inputs[1]\n",
    "                # Search for Constant node producing axes_var\n",
    "                constant_node = None\n",
    "                axes_values = None\n",
    "                for c_node in graph.nodes:\n",
    "                    if (\n",
    "                        c_node.op == \"Constant\"\n",
    "                        and c_node.outputs\n",
    "                        and len(c_node.outputs) == 1\n",
    "                        and c_node.outputs[0].name == axes_var.name\n",
    "                    ):\n",
    "                        constant_node = c_node\n",
    "                        if \"value\" in c_node.attrs:\n",
    "                            axes_values = c_node.attrs[\"value\"].values\n",
    "                            if isinstance(axes_values, np.ndarray):\n",
    "                                axes_values = axes_values.tolist()\n",
    "                        break\n",
    "                if constant_node and axes_values is not None:\n",
    "                    # Update node: remove second input, add axes attr\n",
    "                    node.inputs = [data_input]\n",
    "                    node.attrs[\"axes\"] = axes_values\n",
    "                    # Ensure keepdims is set (default 1 for most reductions)\n",
    "                    if \"keepdims\" not in node.attrs:\n",
    "                        node.attrs[\"keepdims\"] = 1\n",
    "                    fixed_count += 1\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Fixed {node.op} node '{node.name}': axes {axes_values} extracted from Constant '{constant_node.name}'\"\n",
    "                    )\n",
    "                    # Mark for removal; cleanup will handle unused nodes\n",
    "                    removed_constants += 1\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"[{graph_name}] Warning: Could not find/extract axes for {node.op} '{node.name}'; second input '{axes_var.name}', Constant found: {constant_node is not None}\"\n",
    "                    )\n",
    "    if debug_nodes:\n",
    "        print(\n",
    "            f\"[{graph_name}] Total {', '.join(set(dn['op'] for dn in debug_nodes))} nodes: {len(debug_nodes)}, Fixed: {fixed_count}\"\n",
    "        )\n",
    "        for dn in debug_nodes[:3]:  # Print first 3 for brevity\n",
    "            print(\n",
    "                f\"  - {dn['name']}: {dn['op']}, {dn['inputs_count']} inputs, types: {dn['inputs_types']}, second_name: {dn['second_input_name']}\"\n",
    "            )\n",
    "        if len(debug_nodes) > 3:\n",
    "            print(f\"  ... and {len(debug_nodes)-3} more\")\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "def _rename_graph_tensors_and_nodes(\n",
    "    graph: gs.Graph, prefix: str, skip_vars: List[gs.Variable] = None\n",
    "):\n",
    "    \"\"\"Prefix all tensor and node names in `graph` with `prefix`, except variables in skip_vars.\n",
    "\n",
    "    This avoids name collisions when combining multiple graphs. We compare skip_vars by object id to\n",
    "    ensure we don't rename the shared input Variable object.\n",
    "    \"\"\"\n",
    "    if skip_vars is None:\n",
    "        skip_vars = []\n",
    "    skip_ids = {id(v) for v in skip_vars}\n",
    "\n",
    "    # Rename variables (tensors)\n",
    "    tensors = list(graph.tensors().values())\n",
    "    for var in tensors:\n",
    "        if id(var) in skip_ids:\n",
    "            continue\n",
    "        if var.name:\n",
    "            var.name = prefix + var.name\n",
    "\n",
    "    # Rename nodes\n",
    "    for node in graph.nodes:\n",
    "        if node.name:\n",
    "            node.name = prefix + node.name\n",
    "\n",
    "\n",
    "def create_combined_onnx(\n",
    "    model_path1,\n",
    "    model_path2,\n",
    "    whitelist1: List[int],\n",
    "    whitelist2: List[int],\n",
    "    scale_const: float = 3.0,\n",
    "    output_path=\"combined.onnx\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines two ONNX models into one with conditional logic based on whitelists for skin cancer strategy:\n",
    "    - Compute logits1 from model1.\n",
    "    - If argmax(logits1) in whitelist1, use logits1.\n",
    "    - Else compute logits2 from model2.\n",
    "    - If argmax(logits2) in whitelist2, use logits2.\n",
    "    - Else use average of logits1 and logits2.\n",
    "    - Then scale the chosen logits by scale_const and apply softmax for output.\n",
    "\n",
    "    Assumes:\n",
    "    - Both models take 'image' and 'demographics' as inputs.\n",
    "    - Both output a single tensor of shape [batch_size, num_classes] (logits).\n",
    "    - Whitelists are lists of class indices (integers).\n",
    "    - You need to pip install onnx onnx-graphsurgeon if not already installed.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    onnx_model1 = onnx.load(model_path1)\n",
    "    onnx_model2 = onnx.load(model_path2)\n",
    "\n",
    "    # Import into graph surgeon\n",
    "    graph1 = gs.import_onnx(onnx_model1)\n",
    "    graph2 = gs.import_onnx(onnx_model2)\n",
    "\n",
    "    # Fix reduction nodes in BOTH graphs for thoroughness\n",
    "    total_fixed = 0\n",
    "    total_fixed += fix_reduction_nodes(graph1, \"Model1\")\n",
    "    total_fixed += fix_reduction_nodes(graph2, \"Model2\")\n",
    "    if total_fixed == 0:\n",
    "        print(\"No reduction fixes applied - check debug output above\")\n",
    "\n",
    "    # Assume input names and order based on your code\n",
    "    # Rename for clarity\n",
    "    image_input = graph1.inputs[0]\n",
    "    image_input.name = \"image\"\n",
    "\n",
    "    demographics_input = graph1.inputs[1]\n",
    "    demographics_input.name = \"demographics\"\n",
    "\n",
    "    # Share the inputs with model2\n",
    "    old_image_input = graph2.inputs[0]\n",
    "    old_demo_input = graph2.inputs[1]\n",
    "\n",
    "    _rename_graph_tensors_and_nodes(\n",
    "        graph2, prefix=\"g2_\", skip_vars=[old_image_input, old_demo_input]\n",
    "    )\n",
    "\n",
    "    # Replace all references in graph2 nodes to use shared inputs\n",
    "    for node in graph2.nodes:\n",
    "        for i in range(len(node.inputs)):\n",
    "            if node.inputs[i] is old_image_input:\n",
    "                node.inputs[i] = image_input\n",
    "            if node.inputs[i] is old_demo_input:\n",
    "                node.inputs[i] = demographics_input\n",
    "\n",
    "    # Update graph2's inputs list to use the shared inputs\n",
    "    graph2.inputs[0] = image_input\n",
    "    graph2.inputs[1] = demographics_input\n",
    "\n",
    "    # Get outputs (assume single output each)\n",
    "    logits1 = graph1.outputs[0]\n",
    "    logits1.name = \"logits1\"\n",
    "\n",
    "    logits2 = graph2.outputs[0]\n",
    "    logits2.name = \"logits2\"\n",
    "\n",
    "    # Extract num_classes from logits1 shape (assume [batch, num_classes]; batch dynamic)\n",
    "    orig_shape = logits1.shape\n",
    "    if orig_shape and len(orig_shape) >= 2:\n",
    "        num_classes = orig_shape[-1]\n",
    "        if num_classes == 0 or num_classes is None:\n",
    "            num_classes = 11  # Fallback assumption\n",
    "        output_shape = [None, num_classes]  # Dynamic batch\n",
    "    else:\n",
    "        output_shape = [None, 11]  # Fallback\n",
    "        num_classes = 11\n",
    "        print(\n",
    "            f\"Warning: Could not infer num_classes from shape {orig_shape}; using fallback [None, 11]\"\n",
    "        )\n",
    "\n",
    "    print(f\"Inferred output shape: {output_shape}\")\n",
    "\n",
    "    # Define variables\n",
    "    class1 = gs.Variable(\"class1\", shape=[None], dtype=np.int64)\n",
    "    class1_unsq = gs.Variable(\"class1_unsq\", shape=[None, 1], dtype=np.int64)\n",
    "    eq1 = gs.Variable(\"eq1\", shape=[None, len(whitelist1)], dtype=np.bool)\n",
    "    cast1 = gs.Variable(\"cast1\", shape=[None, len(whitelist1)], dtype=np.float32)\n",
    "    reduce1 = gs.Variable(\"reduce1\", shape=[None, 1], dtype=np.float32)\n",
    "    is_in1 = gs.Variable(\"is_in1\", shape=[None, 1], dtype=np.bool)\n",
    "    is_in1_exp = gs.Variable(\"is_in1_exp\", shape=output_shape, dtype=np.bool)\n",
    "\n",
    "    class2 = gs.Variable(\"class2\", shape=[None], dtype=np.int64)\n",
    "    class2_unsq = gs.Variable(\"class2_unsq\", shape=[None, 1], dtype=np.int64)\n",
    "    eq2 = gs.Variable(\"eq2\", shape=[None, len(whitelist2)], dtype=np.bool)\n",
    "    cast2 = gs.Variable(\"cast2\", shape=[None, len(whitelist2)], dtype=np.float32)\n",
    "    reduce2 = gs.Variable(\"reduce2\", shape=[None, 1], dtype=np.float32)\n",
    "    is_in2 = gs.Variable(\"is_in2\", shape=[None, 1], dtype=np.bool)\n",
    "    is_in2_exp = gs.Variable(\"is_in2_exp\", shape=output_shape, dtype=np.bool)\n",
    "\n",
    "    logits_shape_var = gs.Variable(\"logits_shape\", dtype=np.int64, shape=[2])\n",
    "\n",
    "    add_output = gs.Variable(\"add_output\", shape=output_shape, dtype=np.float32)\n",
    "    avg_logits = gs.Variable(\"avg_logits\", shape=output_shape, dtype=np.float32)\n",
    "    inner_selected = gs.Variable(\"inner_selected\", shape=output_shape, dtype=np.float32)\n",
    "    selected_logits = gs.Variable(\n",
    "        \"selected_logits\", shape=output_shape, dtype=np.float32\n",
    "    )\n",
    "    scaled_logits = gs.Variable(\"scaled_logits\", shape=output_shape, dtype=np.float32)\n",
    "    final_output = gs.Variable(\"final_output\", shape=output_shape, dtype=np.float32)\n",
    "\n",
    "    # Constants\n",
    "    whitelist1_const = gs.Constant(\n",
    "        \"whitelist1\", values=np.array(whitelist1, dtype=np.int64)\n",
    "    )\n",
    "    whitelist2_const = gs.Constant(\n",
    "        \"whitelist2\", values=np.array(whitelist2, dtype=np.int64)\n",
    "    )\n",
    "    zero_const = gs.Constant(\"zero\", values=np.array(0.0, dtype=np.float32))\n",
    "    two_const = gs.Constant(\"two\", values=np.array(2.0, dtype=np.float32))\n",
    "    scale_const_node = gs.Constant(\n",
    "        \"scale\", values=np.array(scale_const, dtype=np.float32)\n",
    "    )\n",
    "    axes_unsq = gs.Constant(\"axes_unsq\", values=np.array([1], dtype=np.int64))\n",
    "    axes_reduce = gs.Constant(\"axes_reduce\", values=np.array([1], dtype=np.int64))\n",
    "\n",
    "    # Nodes for whitelist1 check\n",
    "    argmax1 = gs.Node(\n",
    "        op=\"ArgMax\", inputs=[logits1], outputs=[class1], attrs={\"axis\": 1, \"keepdims\": 0}\n",
    "    )\n",
    "    unsqueeze1 = gs.Node(\n",
    "        op=\"Unsqueeze\", inputs=[class1, axes_unsq], outputs=[class1_unsq]\n",
    "    )\n",
    "    equal1 = gs.Node(op=\"Equal\", inputs=[class1_unsq, whitelist1_const], outputs=[eq1])\n",
    "    cast1_node = gs.Node(\n",
    "        op=\"Cast\", inputs=[eq1], outputs=[cast1], attrs={\"to\": onnx.TensorProto.FLOAT}\n",
    "    )\n",
    "    reducesum1 = gs.Node(\n",
    "        op=\"ReduceSum\",\n",
    "        inputs=[cast1, axes_reduce],\n",
    "        outputs=[reduce1],\n",
    "        attrs={\"keepdims\": 1},\n",
    "    )\n",
    "    greater1 = gs.Node(op=\"Greater\", inputs=[reduce1, zero_const], outputs=[is_in1])\n",
    "\n",
    "    # Nodes for whitelist2 check\n",
    "    argmax2 = gs.Node(\n",
    "        op=\"ArgMax\", inputs=[logits2], outputs=[class2], attrs={\"axis\": 1, \"keepdims\": 0}\n",
    "    )\n",
    "    unsqueeze2 = gs.Node(\n",
    "        op=\"Unsqueeze\", inputs=[class2, axes_unsq], outputs=[class2_unsq]\n",
    "    )\n",
    "    equal2 = gs.Node(op=\"Equal\", inputs=[class2_unsq, whitelist2_const], outputs=[eq2])\n",
    "    cast2_node = gs.Node(\n",
    "        op=\"Cast\", inputs=[eq2], outputs=[cast2], attrs={\"to\": onnx.TensorProto.FLOAT}\n",
    "    )\n",
    "    reducesum2 = gs.Node(\n",
    "        op=\"ReduceSum\",\n",
    "        inputs=[cast2, axes_reduce],\n",
    "        outputs=[reduce2],\n",
    "        attrs={\"keepdims\": 1},\n",
    "    )\n",
    "    greater2 = gs.Node(op=\"Greater\", inputs=[reduce2, zero_const], outputs=[is_in2])\n",
    "\n",
    "    # Dynamic shape for expand\n",
    "    shape_node = gs.Node(op=\"Shape\", inputs=[logits1], outputs=[logits_shape_var])\n",
    "\n",
    "    expand1 = gs.Node(\n",
    "        op=\"Expand\", inputs=[is_in1, logits_shape_var], outputs=[is_in1_exp]\n",
    "    )\n",
    "    expand2 = gs.Node(\n",
    "        op=\"Expand\", inputs=[is_in2, logits_shape_var], outputs=[is_in2_exp]\n",
    "    )\n",
    "\n",
    "    # Combine logic\n",
    "    add_logits = gs.Node(op=\"Add\", inputs=[logits1, logits2], outputs=[add_output])\n",
    "    avg_node = gs.Node(op=\"Div\", inputs=[add_output, two_const], outputs=[avg_logits])\n",
    "    inner_where = gs.Node(\n",
    "        op=\"Where\",\n",
    "        inputs=[is_in2_exp, logits2, avg_logits],\n",
    "        outputs=[inner_selected],\n",
    "    )\n",
    "    outer_where = gs.Node(\n",
    "        op=\"Where\",\n",
    "        inputs=[is_in1_exp, logits1, inner_selected],\n",
    "        outputs=[selected_logits],\n",
    "    )\n",
    "    scale_mul = gs.Node(\n",
    "        op=\"Mul\", inputs=[selected_logits, scale_const_node], outputs=[scaled_logits]\n",
    "    )\n",
    "    softmax_final = gs.Node(\n",
    "        op=\"Softmax\", inputs=[scaled_logits], outputs=[final_output], attrs={\"axis\": 1}\n",
    "    )\n",
    "\n",
    "    # Combined graph: nodes from both + new nodes; inputs: image + demographics; output: final_output\n",
    "    combined_graph = gs.Graph(\n",
    "        nodes=graph1.nodes\n",
    "        + graph2.nodes\n",
    "        + [\n",
    "            argmax1,\n",
    "            unsqueeze1,\n",
    "            equal1,\n",
    "            cast1_node,\n",
    "            reducesum1,\n",
    "            greater1,\n",
    "            argmax2,\n",
    "            unsqueeze2,\n",
    "            equal2,\n",
    "            cast2_node,\n",
    "            reducesum2,\n",
    "            greater2,\n",
    "            shape_node,\n",
    "            expand1,\n",
    "            expand2,\n",
    "            add_logits,\n",
    "            avg_node,\n",
    "            inner_where,\n",
    "            outer_where,\n",
    "            scale_mul,\n",
    "            softmax_final,\n",
    "        ],\n",
    "        inputs=[image_input, demographics_input],\n",
    "        outputs=[final_output],\n",
    "    )\n",
    "\n",
    "    # Set opset on the graph for LayerNormalization support (opset 17+)\n",
    "    combined_graph.opset = 17\n",
    "\n",
    "    # Cleanup and export\n",
    "    combined_model = gs.export_onnx(combined_graph.cleanup())\n",
    "\n",
    "    # Infer shapes to fill in any missing (helps checker)\n",
    "    combined_model = shape_inference.infer_shapes(combined_model)\n",
    "\n",
    "    # Optional: Check model\n",
    "    onnx.checker.check_model(combined_model)\n",
    "\n",
    "    # Save\n",
    "    onnx.save(combined_model, output_path)\n",
    "    print(f\"Combined ONNX model saved to {output_path}\")\n",
    "    print(f\"Output shape: {output_shape}\")\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# # Usage example (replace with your actual whitelists)\n",
    "# whitelist61=[0, 3, 4, 10]\n",
    "# whitelist62=[1, 2, 5, 8, 9]  \n",
    "# combined = create_combined_onnx(\n",
    "#     \"../../models/2025-11-27/speechmaster/122_model123.onnx\",\n",
    "#     \"../../models/2025-11-27/speechmaster/18_model118.onnx\",\n",
    "#     whitelist1=whitelist122,\n",
    "#     whitelist2=whitelist18,\n",
    "#     scale_count=3.0,\n",
    "#     output_path=\"../../models/combine/2025-11-27/122vs18_exclusive.onnx\",\n",
    "# )\n",
    "\n",
    "# Usage example (replace with your actual whitelists)\n",
    "whitelist1=[0, 3, 10, 9, 6, 7]\n",
    "whitelist2=[1, 2, 4, 5, 8]  # Example: classes for model2\n",
    "# whitelist1=[0, 3, 10, 9, 6, 7]\n",
    "# whitelist2=[1, 2, 4, 5, 8]  # Example: classes for model2\n",
    "combined = create_combined_onnx(\n",
    "    \"../../models/2025-11-27/speechmaster/62_model94.onnx\",\n",
    "    \"../../models/2025-11-27/grose/61_model08.onnx\",\n",
    "    whitelist1,\n",
    "    whitelist2,\n",
    "    3.0,\n",
    "    \"../../models/combine/2025-11-27/62vs61.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66ef62",
   "metadata": {},
   "source": [
    "#### Strategy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e73a96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined model saved: ../../models/combine/2025-11-27/62_61_exclusive.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "from onnx import shape_inference\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def _fix_reduction_nodes(graph: gs.Graph) -> None:\n",
    "    for node in graph.nodes:\n",
    "        if node.op in {\"ReduceMean\", \"ReduceL2\"} and len(node.inputs) == 2:\n",
    "            data, axes = node.inputs\n",
    "            const = next((n for n in graph.nodes if n.op == \"Constant\" and n.outputs[0] is axes), None)\n",
    "            if const and hasattr(const.attrs[\"value\"], \"values\"):\n",
    "                node.inputs = [data]\n",
    "                node.attrs[\"axes\"] = const.attrs[\"value\"].values.tolist()\n",
    "                node.attrs[\"keepdims\"] = 1\n",
    "\n",
    "\n",
    "def _share_inputs_and_rename(g1: gs.Graph, g2: gs.Graph, prefix: str = \"m2_\"):\n",
    "    img = g1.inputs[0]\n",
    "    demo = g1.inputs[1]\n",
    "    img.name = \"image\"\n",
    "    demo.name = \"demographics\"\n",
    "\n",
    "    old_img, old_demo = g2.inputs[0], g2.inputs[1]\n",
    "    skip = {id(old_img), id(old_demo)}\n",
    "    for v in g2.tensors().values():\n",
    "        if id(v) not in skip and v.name:\n",
    "            v.name = prefix + v.name\n",
    "    for n in g2.nodes:\n",
    "        if n.name:\n",
    "            n.name = prefix + n.name\n",
    "\n",
    "    for n in g2.nodes:\n",
    "        for i, inp in enumerate(n.inputs):\n",
    "            if inp is old_img:\n",
    "                n.inputs[i] = img\n",
    "            if inp is old_demo:\n",
    "                n.inputs[i] = demo\n",
    "    g2.inputs = [img, demo]\n",
    "    return img, demo\n",
    "\n",
    "\n",
    "def create_combined_onnx(\n",
    "    model_path1: str,\n",
    "    model_path2: str,\n",
    "    whitelist1: List[int],\n",
    "    whitelist2: List[int],\n",
    "    scale_factor: float = 3.0,\n",
    "    output_path: str = \"combined.onnx\",\n",
    ") -> onnx.ModelProto:\n",
    "    # Load & prepare graphs\n",
    "    g1 = gs.import_onnx(onnx.load(model_path1))\n",
    "    g2 = gs.import_onnx(onnx.load(model_path2))\n",
    "    _fix_reduction_nodes(g1)\n",
    "    _fix_reduction_nodes(g2)\n",
    "    img_input, demo_input = _share_inputs_and_rename(g1, g2, \"m2_\")\n",
    "\n",
    "    logits1 = g1.outputs[0]\n",
    "    logits2 = g2.outputs[0]\n",
    "    logits1.name = \"logits_m1\"\n",
    "    logits2.name = \"logits_m2\"\n",
    "\n",
    "    num_classes = logits1.shape[1] if logits1.shape and len(logits1.shape) == 2 else 11\n",
    "    batch_shape = (None, num_classes)\n",
    "\n",
    "    # Constants\n",
    "    w1 = gs.Constant(\"w1\", np.array(whitelist1, np.int64))\n",
    "    w2 = gs.Constant(\"w2\", np.array(whitelist2, np.int64))\n",
    "    zero = gs.Constant(\"zero\", np.array(0.0, np.float32))\n",
    "    two = gs.Constant(\"two\", np.array(2.0, np.float32))\n",
    "    scale = gs.Constant(\"scale\", np.array(scale_factor, np.float32))\n",
    "    axis1 = gs.Constant(\"axis1\", np.array([1], np.int64))\n",
    "\n",
    "    # Helper: membership test that works with ReduceSum\n",
    "    def membership_nodes(class_unsq: gs.Variable, whitelist_const: gs.Constant, prefix: str):\n",
    "        eq = gs.Variable(f\"{prefix}_eq\", dtype=np.bool)\n",
    "        cast = gs.Variable(f\"{prefix}_cast\", dtype=np.float32)\n",
    "        reduced = gs.Variable(f\"{prefix}_reduced\", dtype=np.float32, shape=[\"batch\", 1])\n",
    "        is_member = gs.Variable(f\"{prefix}_member\", dtype=np.bool, shape=[\"batch\", 1])\n",
    "\n",
    "        nodes = [\n",
    "            gs.Node(op=\"Equal\", name=f\"eq_{prefix}\", inputs=[class_unsq, whitelist_const], outputs=[eq]),\n",
    "            gs.Node(op=\"Cast\", name=f\"cast_{prefix}\", inputs=[eq], outputs=[cast],\n",
    "                    attrs={\"to\": onnx.TensorProto.FLOAT}),\n",
    "            gs.Node(op=\"ReduceSum\", name=f\"red_{prefix}\", inputs=[cast, axis1],\n",
    "                    outputs=[reduced], attrs={\"keepdims\": 1}),\n",
    "            gs.Node(op=\"Greater\", name=f\"gt_{prefix}\", inputs=[reduced, zero], outputs=[is_member]),\n",
    "        ]\n",
    "        return nodes, is_member\n",
    "\n",
    "    # ArgMax + Unsqueeze\n",
    "    c1 = gs.Variable(\"c1\", np.int64, [\"batch\"])\n",
    "    c2 = gs.Variable(\"c2\", np.int64, [\"batch\"])\n",
    "    c1_u = gs.Variable(\"c1_u\", np.int64, [\"batch\", 1])\n",
    "    c2_u = gs.Variable(\"c2_u\", np.int64, [\"batch\", 1])\n",
    "\n",
    "    nodes = [\n",
    "        gs.Node(op=\"ArgMax\", name=\"argmax1\", inputs=[logits1], outputs=[c1], attrs={\"axis\": 1, \"keepdims\": 0}),\n",
    "        gs.Node(op=\"ArgMax\", name=\"argmax2\", inputs=[logits2], outputs=[c2], attrs={\"axis\": 1, \"keepdims\": 0}),\n",
    "        gs.Node(op=\"Unsqueeze\", name=\"unsq1\", inputs=[c1, axis1], outputs=[c1_u]),\n",
    "        gs.Node(op=\"Unsqueeze\", name=\"unsq2\", inputs=[c2, axis1], outputs=[c2_u]),\n",
    "    ]\n",
    "\n",
    "    # Membership checks\n",
    "    n1, m1_in_w1 = membership_nodes(c1_u, w1, \"m1_w1\")\n",
    "    n2, m1_in_w2 = membership_nodes(c1_u, w2, \"m1_w2\")\n",
    "    n3, m2_in_w1 = membership_nodes(c2_u, w1, \"m2_w1\")\n",
    "    n4, m2_in_w2 = membership_nodes(c2_u, w2, \"m2_w2\")\n",
    "    nodes += n1 + n2 + n3 + n4\n",
    "\n",
    "    # Conditions\n",
    "    m1_not_w2 = gs.Variable(\"m1_not_w2\", np.bool, [\"batch\", 1])\n",
    "    m2_not_w1 = gs.Variable(\"m2_not_w1\", np.bool, [\"batch\", 1])\n",
    "    use_m1 = gs.Variable(\"use_model1\", np.bool, [\"batch\", 1])\n",
    "    use_m2 = gs.Variable(\"use_model2\", np.bool, [\"batch\", 1])\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Not\", name=\"not1\", inputs=[m1_in_w2], outputs=[m1_not_w2]),\n",
    "        gs.Node(op=\"Not\", name=\"not2\", inputs=[m2_in_w1], outputs=[m2_not_w1]),\n",
    "        gs.Node(op=\"And\", name=\"and_m1\", inputs=[m1_in_w1, m1_not_w2], outputs=[use_m1]),\n",
    "        gs.Node(op=\"And\", name=\"and_m2\", inputs=[m2_not_w1, m2_in_w2], outputs=[use_m2]),\n",
    "    ]\n",
    "\n",
    "    # Expand masks\n",
    "    shape_var = gs.Variable(\"shape\", np.int64, [2])\n",
    "    use_m1_exp = gs.Variable(\"use_m1_exp\", np.bool, batch_shape)\n",
    "    use_m2_exp = gs.Variable(\"use_m2_exp\", np.bool, batch_shape)\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Shape\", name=\"shape\", inputs=[logits1], outputs=[shape_var]),\n",
    "        gs.Node(op=\"Expand\", name=\"exp_m1\", inputs=[use_m1, shape_var], outputs=[use_m1_exp]),\n",
    "        gs.Node(op=\"Expand\", name=\"exp_m2\", inputs=[use_m2, shape_var], outputs=[use_m2_exp]),\n",
    "    ]\n",
    "\n",
    "    # Average fallback\n",
    "    sum_ab = gs.Variable(\"sum\", np.float32, batch_shape)\n",
    "    avg = gs.Variable(\"avg\", np.float32, batch_shape)\n",
    "    temp = gs.Variable(\"temp\", np.float32, batch_shape)\n",
    "    selected = gs.Variable(\"selected\", np.float32, batch_shape)\n",
    "    scaled = gs.Variable(\"scaled\", np.float32, batch_shape)\n",
    "    probs = gs.Variable(\"probabilities\", np.float32, batch_shape)\n",
    "\n",
    "    nodes += [\n",
    "        gs.Node(op=\"Add\", name=\"add\", inputs=[logits1, logits2], outputs=[sum_ab]),\n",
    "        gs.Node(op=\"Div\", name=\"div\", inputs=[sum_ab, two], outputs=[avg]),\n",
    "        gs.Node(op=\"Where\", name=\"where_m2\", inputs=[use_m2_exp, logits2, avg], outputs=[temp]),\n",
    "        gs.Node(op=\"Where\", name=\"where_final\", inputs=[use_m1_exp, logits1, temp], outputs=[selected]),\n",
    "        gs.Node(op=\"Mul\", name=\"mul\", inputs=[selected, scale], outputs=[scaled]),\n",
    "        gs.Node(op=\"Softmax\", name=\"softmax\", inputs=[scaled], outputs=[probs], attrs={\"axis\": 1}),\n",
    "    ]\n",
    "\n",
    "    # Final graph\n",
    "    graph = gs.Graph(nodes=g1.nodes + g2.nodes + nodes,\n",
    "                     inputs=[img_input, demo_input],\n",
    "                     outputs=[probs],\n",
    "                     opset=17)\n",
    "\n",
    "    model = gs.export_onnx(graph.cleanup().toposort())\n",
    "    model = shape_inference.infer_shapes(model)\n",
    "    onnx.checker.check_model(model, full_check=True)   # now passes!\n",
    "    onnx.save(model, output_path)\n",
    "    print(f\"Combined model saved: {output_path}\")\n",
    "    # return model\n",
    "\n",
    "\n",
    "# === RUN ===\n",
    "create_combined_onnx(\n",
    "    model_path1=\"../../models/2025-11-27/speechmaster/62_model94.onnx\",\n",
    "    model_path2=\"../../models/2025-11-27/grose/61_model08.onnx\",\n",
    "    whitelist1=[0, 3, 10, 9, 6, 7],\n",
    "    whitelist2=[1, 2, 4, 5, 8],\n",
    "    scale_factor=3.0,\n",
    "    output_path=\"../../models/combine/2025-11-27/62_61_exclusive.onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996623bd",
   "metadata": {},
   "source": [
    "### Down version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa117114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the original model\n",
    "model = onnx.load(f\"../../models/combine/2025-11-27/18vs122_1.onnx\")\n",
    "\n",
    "# Check original details (optional: for debugging)\n",
    "print(\"Original IR version:\", model.ir_version)\n",
    "print(\"Original opset versions:\", [(imp.domain, imp.version) for imp in model.opset_import])\n",
    "\n",
    "# Downgrade IR version to 11 (your runtime's max)\n",
    "model.ir_version = 10\n",
    "\n",
    "# Save the downgraded model\n",
    "downgraded_path = f\"../../models/combine/2025-11-27/18vs122_1_down.onnx\"\n",
    "onnx.save(model, downgraded_path)\n",
    "print(f\"Downgraded model saved to: {downgraded_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import onnx\n",
    "from onnx.helper import (\n",
    "    make_node, make_graph, make_model, make_tensor_value_info)\n",
    "from onnx.numpy_helper import from_array\n",
    "from onnx.checker import check_model\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "# initializers\n",
    "value = numpy.array([0], dtype=numpy.float32)\n",
    "zero = from_array(value, name='zero')\n",
    "\n",
    "# Same as before, X is the input, Y is the output.\n",
    "X = make_tensor_value_info('X', onnx.TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', onnx.TensorProto.FLOAT, [None])\n",
    "\n",
    "# The node building the condition. The first one\n",
    "# sum over all axes.\n",
    "rsum = make_node('ReduceSum', ['X'], ['rsum'])\n",
    "# The second compares the result to 0.\n",
    "cond = make_node('Greater', ['rsum', 'zero'], ['cond'])\n",
    "\n",
    "# Builds the graph is the condition is True.\n",
    "# Input for then\n",
    "then_out = make_tensor_value_info(\n",
    "    'then_out', onnx.TensorProto.FLOAT, None)\n",
    "# The constant to return.\n",
    "then_cst = from_array(numpy.array([1]).astype(numpy.float32))\n",
    "\n",
    "# The only node.\n",
    "then_const_node = make_node(\n",
    "    'Constant', inputs=[],\n",
    "    outputs=['then_out'],\n",
    "    value=then_cst, name='cst1')\n",
    "\n",
    "# And the graph wrapping these elements.\n",
    "then_body = make_graph(\n",
    "    [then_const_node], 'then_body', [], [then_out])\n",
    "\n",
    "# Same process for the else branch.\n",
    "else_out = make_tensor_value_info(\n",
    "    'else_out', onnx.TensorProto.FLOAT, [5])\n",
    "else_cst = from_array(numpy.array([-1]).astype(numpy.float32))\n",
    "\n",
    "else_const_node = make_node(\n",
    "    'Constant', inputs=[],\n",
    "    outputs=['else_out'],\n",
    "    value=else_cst, name='cst2')\n",
    "\n",
    "else_body = make_graph(\n",
    "    [else_const_node], 'else_body',\n",
    "    [], [else_out])\n",
    "\n",
    "# Finally the node If taking both graphs as attributes.\n",
    "if_node = onnx.helper.make_node(\n",
    "    'If', ['cond'], ['Y'],\n",
    "    then_branch=then_body,\n",
    "    else_branch=else_body)\n",
    "\n",
    "# The final graph.\n",
    "graph = make_graph([rsum, cond, if_node], 'if', [X], [Y], [zero])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# Let's freeze the opset.\n",
    "del onnx_model.opset_import[:]\n",
    "opset = onnx_model.opset_import.add()\n",
    "opset.domain = ''\n",
    "opset.version = 15\n",
    "onnx_model.ir_version = 8\n",
    "\n",
    "# Save.\n",
    "with open(\"onnx_if_sign.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "# Let's see the output.\n",
    "sess = InferenceSession(onnx_model.SerializeToString(),\n",
    "                        providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "x = numpy.ones((3, 2), dtype=numpy.float32)\n",
    "res = sess.run(None, {'X': x})\n",
    "\n",
    "# It works.\n",
    "print(\"result\", res)\n",
    "print()\n",
    "\n",
    "# Some display.\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee6b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
